{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "wolabor2017 = pd.read_csv('CDC2017wolabor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of 'U' of AB_NICU\n",
    "wolabor2017 =  wolabor2017[wolabor2017['AB_NICU'].isin(['Y', 'N'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split out holdout test set\n",
    "def split_sets(dataframe, seed, test_prop=0.1): \n",
    "    '''\n",
    "    - A function that splits specifically a dataframe into a train and test portion\n",
    "    - Requires multiple assignment: train, test\n",
    "    ---------------\n",
    "    - dataframe: dataframe to be split\n",
    "    - seed: set seed for reproducability\n",
    "    - test_prop: takes a float - proportion of dataframe that should be allocated to the test set\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    testIdxes = np.random.choice(range(0,dataframe.shape[0]), size=round(dataframe.shape[0]*test_prop), replace=False)\n",
    "    trainIdxes = list(set(range(0,dataframe.shape[0])) - set(testIdxes))\n",
    "\n",
    "    train = dataframe.iloc[trainIdxes,:]\n",
    "    test  = dataframe.iloc[testIdxes,:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_sets(wolabor2017, 0, test_prop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3475154, 54)\n",
      "(386128, 54)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsample = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample function, thanks Bettina and Aron!\n",
    "def downsample_df (df):\n",
    "\n",
    "    '''\n",
    "    Remove undefined information on NICU admissions (AB_NICU == 'U'),\n",
    "    create a binary target vector, and create a \"balanced\" dataframe\n",
    "    with all NICU admissions and matching numbers of randomly selected non-NICU admissions.\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # remove unknown class from df\n",
    "    df_no_unknown = df[df['AB_NICU'].isin(['Y', 'N'])]\n",
    "\n",
    "    # Create binary target vector, NICU = yes classified as class 0\n",
    "    df_y_n = np.where((df_no_unknown['AB_NICU'] == 'Y'), 0, 1)\n",
    "\n",
    "    # Get indicies of each class' observations\n",
    "    index_class0 = np.where(df_y_n == 0)[0]\n",
    "    index_class1 = np.where(df_y_n == 1)[0]\n",
    "\n",
    "    # Get numbers of observations in class 0\n",
    "    n_class0 = len(index_class0)\n",
    "\n",
    "    # Randomly sample the same number of observations from class 1 as in class 0, without replacement\n",
    "    np.random.seed(0)\n",
    "    index_class1_downsampled = np.random.choice(index_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Create dataframes for NICU and downsampled non-NICU\n",
    "    df_defect = df_no_unknown.iloc[index_class0]\n",
    "    df_adj_NONdefect = df_no_unknown.iloc[index_class1_downsampled]\n",
    "\n",
    "    # Append into 1 dataframe\n",
    "    df_downsampled = df_defect.append(df_adj_NONdefect)\n",
    "\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampled\n",
    "dsample = downsample_df(dsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311671\n",
      "(623342, 54)\n",
      "311671\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "print(sum(train.AB_NICU == 'Y')) \n",
    "print(dsample.shape)   \n",
    "print(sum(dsample.AB_NICU == 'Y'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoding Function. Thanks Ira!\n",
    "def LabelEncoding(dataframe):\n",
    "    '''\n",
    "    Function that takes a dataframe and transforms it with label encoding on all the categorical features.\n",
    "    '''\n",
    "    \n",
    "    #create a list using object types since dataframe.dtypes.value_counts() only shows objects and int64\n",
    "    objlist = list(dataframe.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    #change type then transform column using cat codes\n",
    "    for col in objlist:\n",
    "        dataframe[col] = dataframe[col].astype('category')\n",
    "        dataframe[col] = dataframe[col].cat.codes\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bee/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/bee/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#Label Encoded\n",
    "dsample = LabelEncoding(dsample)\n",
    "dtest = LabelEncoding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def targetchoice(column,dataframe):\n",
    "    '''\n",
    "    Takes a column and a dataframe, returns four values for;\n",
    "    x_train, X_test, y_train, and y_test\n",
    "    '''\n",
    "    #Cutting the data and target dataframes\n",
    "    sample_data = dataframe.loc[:, dsample.columns != column ]\n",
    "    sample_target = dataframe.loc[:,column]\n",
    "    \n",
    "    #assigning to variables\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sample_data, sample_target, test_size=0.2, random_state=0)\n",
    "    \n",
    "    #appending to a list to return for multi-assignment\n",
    "    varlist = []\n",
    "    varlist.append(X_train)\n",
    "    varlist.append(X_test)\n",
    "    varlist.append(y_train)\n",
    "    varlist.append(y_test)\n",
    "    return varlist\n",
    "\n",
    "#format is \"X_train, X_test, y_train, y_test = targetchoice()\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = targetchoice('AB_NICU',dsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dsample.drop('AB_NICU', axis=1)\n",
    "y_train = dsample['AB_NICU']\n",
    "X_test = dtest.drop('AB_NICU', axis=1)\n",
    "y_test = dtest['AB_NICU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623342, 53)\n",
      "(386128, 53)\n",
      "(623342,)\n",
      "(386128,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.32184\n",
      "The test error is: 0.24791\n"
     ]
    }
   ],
   "source": [
    "#XGBoost initial fit \n",
    "xgb = XGBClassifier()\n",
    "xgb.set_params(random_state=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"The training error is: %.5f\" % (1 - xgb.score(X_train, y_train)))\n",
    "print(\"The test error is: %.5f\" % (1 - xgb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter grid\n",
    "xgb_param_grid ={'learning_rate': [0.05]\n",
    "                 'max_depth': [6],\n",
    "                 'min_child_weight': [5],\n",
    "                 'n_estimators': [200]}\n",
    "\n",
    "#grid search\n",
    "grid_search_xgb = GridSearchCV(xgb, xgb_param_grid, scoring='accuracy', cv= 5, n_jobs=-1, return_train_score = True)\n",
    "%time grid_search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best parameters\n",
    "print(grid_search_xgb.best_params_)\n",
    "print(grid_search_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training/test errors\n",
    "print(\"The training error is: %.5f\" % (1 - grid_search_forest.best_estimator_.score(X_train, y_train)))\n",
    "print(\"The test error is: %.5f\" % (1 - grid_search_forest.best_estimator_.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction with tuned hyperparameters\n",
    "grid_xgb_pred = grid_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printErrors(Y_test, grid_xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances_xgb = list(xgb.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_xgb = [(feature, round(importance, 5)) for feature, importance in zip(X_train.columns, importances_xgb)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "xgb_feature_importances = sorted(feature_importances_xgb, key = lambda x: x[1], reverse = True )\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:10} Importance: {}'.format(*pair)) for pair in xgb_feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feature_importances_top20 = xgb_feature_importances[:20]\n",
    "featureNames, featureScores = zip(*list(xgb_feature_importances_top20))\n",
    "xgb_feature_importances_top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(len(featureScores)), featureScores, tick_label=featureNames)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('feature importance')\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importances')\n",
    "plt.savefig('xgbFI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_tuned_model = grid_search_xgb.best_estimator_\n",
    "xgb_feature_importance = 100.0 * (xgb_params_tuned_model.feature_importances_ / xgb_params_tuned_model.feature_importances_.max())\n",
    "xgb_important_features = X_train.columns[xgb_feature_importance >= 2]\n",
    "xgb_unimportant_features = X_train.columns[xgb_feature_importance < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, gs_logit.best_estimator_.predict(X_test))\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
