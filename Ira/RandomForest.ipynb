{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "\n",
    "# trimmed2018 = pd.read_csv('cdc2018trimmed.csv') #(84)\n",
    "\n",
    "# csv2018 = pd.read_csv('CSV2018.csv') # with bettina's function as well, (98 lol)\n",
    "\n",
    "# trimwolabor2018 = pd.read_csv('cdc2018wolabor.csv') #(68)\n",
    "\n",
    "# trimmed2 = pd.read_csv('cdc2018trimmed2.csv') #(84)\n",
    "\n",
    "# trimmed2016 = pd.read_csv(\"CDC2016trimmed.csv\") #84.9\n",
    "\n",
    "# trimwolabor2016 = pd.read_csv('CDC2016wolabor.csv') #67.3\n",
    "\n",
    "trimmed2017 = pd.read_csv('CDC2017trimmed.csv') #84.8\n",
    "#predictors\n",
    "# [b'OEGest_R10',\n",
    "#  b'AB_AVEN1',\n",
    "#  b'GESTREC10',\n",
    "#  b'BWTR12',\n",
    "#  b'AB_SURF',\n",
    "#  b'APGAR5',\n",
    "#  b'DOB_TT',\n",
    "#  b'ME_ROUT',\n",
    "#  b'DOB_MM',\n",
    "#  b'PREVIS_REC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsample = trimmed2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample function, thanks Bettina and Aron!\n",
    "def downsample_df (df):\n",
    "\n",
    "    '''\n",
    "    Remove undefined information on NICU admissions (AB_NICU == 'U'),\n",
    "    create a binary target vector, and create a \"balanced\" dataframe\n",
    "    with all NICU admissions and matching numbers of randomly selected non-NICU admissions.\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # remove unknown class from df\n",
    "    df_no_unknown = df[df['AB_NICU'].isin(['Y', 'N'])]\n",
    "\n",
    "    # Create binary target vector, NICU = yes classified as class 0\n",
    "    df_y_n = np.where((df_no_unknown['AB_NICU'] == 'Y'), 0, 1)\n",
    "\n",
    "    # Get indicies of each class' observations\n",
    "    index_class0 = np.where(df_y_n == 0)[0]\n",
    "    index_class1 = np.where(df_y_n == 1)[0]\n",
    "\n",
    "    # Get numbers of observations in class 0\n",
    "    n_class0 = len(index_class0)\n",
    "\n",
    "    # Randomly sample the same number of observations from class 1 as in class 0, without replacement\n",
    "    np.random.seed(0)\n",
    "    index_class1_downsampled = np.random.choice(index_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Create dataframes for NICU and downsampled non-NICU\n",
    "    df_defect = df_no_unknown.iloc[index_class0]\n",
    "    df_adj_NONdefect = df_no_unknown.iloc[index_class1_downsampled]\n",
    "\n",
    "    # Append into 1 dataframe\n",
    "    df_downsampled = df_defect.append(df_adj_NONdefect)\n",
    "\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampled\n",
    "dsample = downsample_df(dsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduced_df (df, list_to_drop):\n",
    "\n",
    "    '''\n",
    "    Function to choose columns from dataframe for label encoding. Takes the data frame and the columns to drop\n",
    "    as a list.\n",
    "    '''\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # create list of flags, territory info and imputed info likely to be dropped together\n",
    "    flags = list(filter(lambda i: re.search('\\AF_',i) , df.columns))\n",
    "    territory_info = ['OCTERR','OCNTYFIPS', 'OCNTYPOP', 'MBCNTRY', 'MRCNTRY', 'MRTERR', 'RCNTY', 'RCNTY_POP', 'RCNTY_POP',\n",
    "                 'RCITY_POP', 'RECTYPE']\n",
    "    imputed_info = ['MAGE_IMPFLG', 'MAGE_REPFLG', 'MRACEIMP','MAR_IMP', 'FAGERPT_FLG', 'IMP_PLUR', 'IMP_SEX',\n",
    "                'COMPGST_IMP', 'OBGEST_FLG', 'LMPUSED']\n",
    "\n",
    "    # create a copy of dataframe\n",
    "    df2 = df.copy()\n",
    "\n",
    "    # compare columns in case they have already been dropped in the input df\n",
    "    \n",
    "\n",
    "    # drop columns\n",
    "    for feature in list_to_drop:\n",
    "        #if ~feature.isin(df2.colunms):\n",
    "        #    except ValueError:\n",
    "        #    print(\"Column name does not exist\")\n",
    "        if feature == 'flag':\n",
    "            df2.drop(flags, inplace = True, axis=1)\n",
    "        elif feature == 'territory':\n",
    "            df2.drop(territory_info, inplace = True, axis=1)\n",
    "        elif feature == 'imputed':\n",
    "            df2.drop(imputed_info, inplace = True, axis=1)\n",
    "        else:\n",
    "            df2.drop(feature, inplace = True, axis=1)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of flags, territory info and imputed info likely to be dropped together\n",
    "#only to be used with FULL data sets (ie: CSV2018)\n",
    "flags = list(filter(lambda i: re.search('\\AF_',i) , dsample.columns))\n",
    "territory_info = ['OCTERR','OCNTYFIPS', 'OCNTYPOP', 'MBCNTRY', 'MRCNTRY', 'MRTERR', 'RCNTY', 'RCNTY_POP',\n",
    "                 'RCITY_POP', 'RECTYPE']\n",
    "imputed_info = ['MAGE_IMPFLG', 'MAGE_REPFLG', 'MRACEIMP','MAR_IMP', 'FAGERPT_FLG', 'IMP_PLUR', 'IMP_SEX',\n",
    "                'COMPGST_IMP', 'OBGEST_FLG', 'LMPUSED']\n",
    "dsample = create_reduced_df(dsample,flags)\n",
    "dsample = create_reduced_df(dsample,territory_info)\n",
    "dsample = create_reduced_df(dsample,imputed_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoding Function. Thanks Ira!\n",
    "def LabelEncoding(dataframe):\n",
    "    '''\n",
    "    Function that takes a dataframe and transforms it with label encoding on all the categorical features.\n",
    "    '''\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    #create a list using object types since dataframe.dtypes.value_counts() only shows objects and int64\n",
    "    objlist = list(dataframe.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    #change type then transform column using cat codes\n",
    "    for col in objlist:\n",
    "        dataframe[col] = dataframe[col].astype('category')\n",
    "        dataframe[col] = dataframe[col].cat.codes\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoded\n",
    "dsample = LabelEncoding(dsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetchoice(column,dataframe):\n",
    "    '''\n",
    "    Takes a column and a dataframe, returns four values for;\n",
    "    x_train, X_test, y_train, and y_test\n",
    "    '''\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    #Cutting the data and target dataframes\n",
    "    sample_data = dataframe.loc[:, dsample.columns != column ]\n",
    "    sample_target = dataframe.loc[:,column]\n",
    "    \n",
    "    #assigning to variables\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sample_data, sample_target, test_size=0.2, random_state=0)\n",
    "    \n",
    "    #appending to a list to return for multi-assignment\n",
    "    varlist = []\n",
    "    varlist.append(X_train)\n",
    "    varlist.append(X_test)\n",
    "    varlist.append(y_train)\n",
    "    varlist.append(y_test)\n",
    "    return varlist\n",
    "\n",
    "#format is \"X_train, X_test, y_train, y_test = targetchoice()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = targetchoice('AB_NICU',dsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns[X_train.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.loc[:, \"DMAR\"] = X_train.loc[:, \"DMAR\"].fillna(9.0)\n",
    "# X_test.loc[:, \"DMAR\"] = X_test.loc[:, \"DMAR\"].fillna(9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.01313\n",
      "The test     error is: 0.15872\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST INITIAL FIT-\n",
    "randomForest = ensemble.RandomForestClassifier()\n",
    "randomForest.set_params(random_state=0)\n",
    "randomForest.fit(X_train, y_train) \n",
    "print(\"The training error is: %.5f\" % (1 - randomForest.score(X_train, y_train)))\n",
    "print(\"The test     error is: %.5f\" % (1 - randomForest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 5.02 s, total: 1min 32s\n",
      "Wall time: 55min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': range(1, 16), 'n_estimators': range(10, 50, 30)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameter grid\n",
    "grid_para_forest = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 16),\n",
    "    'n_estimators': range(10, 50, 30)\n",
    "}\n",
    "# grid search\n",
    "grid_search_forest = ms.GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5, n_jobs=-1,)\n",
    "%time grid_search_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 15, 'n_estimators': 40}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8488612425694003"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Params so far: {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 40}\n",
    "# 0.8431166186317793\n",
    "print(grid_search_forest.best_params_)\n",
    "grid_search_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.14521\n",
      "The test     error is: 0.15078\n"
     ]
    }
   ],
   "source": [
    "# get the training/test errors\n",
    "print(\"The training error is: %.5f\" % (1 - grid_search_forest.best_estimator_.score(X_train, y_train)))\n",
    "print(\"The test     error is: %.5f\" % (1 - grid_search_forest.best_estimator_.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'OEGest_R10',\n",
       " b'AB_AVEN1',\n",
       " b'GESTREC10',\n",
       " b'BWTR12',\n",
       " b'AB_SURF',\n",
       " b'APGAR5',\n",
       " b'DOB_TT',\n",
       " b'ME_ROUT',\n",
       " b'DOB_MM',\n",
       " b'PREVIS_REC']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of feature importance\n",
    "feature_importance = list(zip(dsample.columns, randomForest.feature_importances_))\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')]\n",
    "feature_importance = np.array(feature_importance, dtype=dtype)\n",
    "feature_sort = np.sort(feature_importance, order='importance')[::-1]\n",
    "[i for (i, j) in feature_sort[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting feature importance\n",
    "sorted_features = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "features_top10 = sorted_features[:10]\n",
    "featureNames, featureScores = zip(*list(features_top10))\n",
    "plt.barh(range(len(featureScores)), featureScores, tick_label=featureNames)\n",
    "plt.title('feature importance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thanks Drucila!\n",
    "feature_importance = 100.0 * (randomForest.feature_importances_ / randomForest.feature_importances_.max())\n",
    "important_features = X_train.columns[feature_importance >= 10]\n",
    "unimportant_features = X_train.columns[feature_importance < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
