{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmwETmEnyVUg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_columns = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sO3LPgaEyVUp"
   },
   "outputs": [],
   "source": [
    "#function to run simple SQL query from python\n",
    "def create_table_from_SQL(user, database, password, query):\n",
    "    '''\n",
    "    - A function that returns a pandas dataframe from a SQL query in python\n",
    "    ---------------\n",
    "    - user: user for your local SQL connection in string format\n",
    "    - database: schema name where your database is stored in string format\n",
    "    - password: password to access your local SQL connection in string format\n",
    "    - query: SQL query in string format; enclose with double quotes and use single quotes\n",
    "    to designate VARCHAR values within queries; use schema_name.table_name after FROM statement\n",
    "    '''\n",
    "    import mysql.connector\n",
    "    cnx = mysql.connector.connect(user=user, database=database, password=password)\n",
    "    cursor = cnx.cursor()\n",
    "    query = query\n",
    "    cursor.execute(query)\n",
    "    df = pd.DataFrame(cursor.fetchall())\n",
    "    df.columns = cursor.column_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gS0Bl1I4yVUs"
   },
   "outputs": [],
   "source": [
    "#modified version of Bettina's function which creates downsampled dataset for specific defects\n",
    "#vs overall NICU admissions\n",
    "\n",
    "def downsample_df (df, variable):\n",
    "\n",
    "    '''\n",
    "    Remove undefined information on defect presence admissions (defect == 'U'),\n",
    "    create a binary target vector, and create a \"balanced\" dataframe\n",
    "    with all defect cases and matching numbers of randomly selected non-defect cases.\n",
    "    --------------------\n",
    "    df: full dataframe\n",
    "    variable: variable or defect of interest in string format\n",
    "    '''\n",
    "\n",
    "    # remove unknown class from df\n",
    "    df_no_unknown = df[df[variable].isin(['Y', 'N'])]\n",
    "\n",
    "    # Create binary target vector, NICU = yes classified as class 0\n",
    "    df_y_n = pd.DataFrame(np.where((df_no_unknown[variable] == 'Y'), 0, 1))\n",
    "\n",
    "    # Get indicies of each class' observations\n",
    "    index_class0 = np.where(df_y_n == 0)[0]\n",
    "    index_class1 = np.where(df_y_n == 1)[0]\n",
    "\n",
    "    # Get numbers of observations in class 0\n",
    "    n_class0 = len(index_class0)\n",
    "\n",
    "    # Randomly sample the same number of observations from class 1 as in class 0, without replacement\n",
    "    np.random.seed(0)\n",
    "    index_class1_downsampled = np.random.choice(index_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Create dataframes for NICU and downsampled non-NICU\n",
    "    df_defect = df_no_unknown.iloc[index_class0]\n",
    "    df_adj_NONdefect = df_no_unknown.iloc[index_class1_downsampled]\n",
    "\n",
    "    # Append into 1 dataframe\n",
    "    df_downsampled = df_defect.append(df_adj_NONdefect)\n",
    "\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uKbVMwKyVUv"
   },
   "outputs": [],
   "source": [
    "# function to split out holdout test set\n",
    "def split_sets(dataframe, seed, test_prop=0.1): \n",
    "    '''\n",
    "    - A function that splits specifically a dataframe into a train and test portion\n",
    "    - Requires multiple assignment: train, test\n",
    "    ---------------\n",
    "    - dataframe: dataframe to be split\n",
    "    - seed: set seed for reproducability\n",
    "    - test_prop: takes a float - proportion of dataframe that should be allocated to the test set\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    testIdxes = np.random.choice(range(0,dataframe.shape[0]), size=round(dataframe.shape[0]*test_prop), replace=False)\n",
    "    trainIdxes = list(set(range(0,dataframe.shape[0])) - set(testIdxes))\n",
    "\n",
    "    train = dataframe.iloc[trainIdxes,:]\n",
    "    test  = dataframe.iloc[testIdxes,:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXHFMWdVyVUx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-K5HuY8yVU0"
   },
   "outputs": [],
   "source": [
    "def mlp_convert_cont_floats(df):\n",
    "    #convert continuous variables to float\n",
    "    #update to split out ordinal categorical separately\n",
    "    for x in variables['continuous']:\n",
    "        df[x]=df[x].astype('float')\n",
    "    return df\n",
    "\n",
    "def mlp_convert_nom_cat(df):\n",
    "    #convert nominal categorical variables to category\n",
    "    for x in variables['nominal_categorical']:\n",
    "        df[x]=df[x].astype('category')\n",
    "    return df\n",
    "\n",
    "def mlp_convert_ord_cat(df):\n",
    "    #convert ordinal categorical variables\n",
    "    df.DOB_MM = df.DOB_MM.astype('category')\n",
    "    df.PRECARE = df.PRECARE.astype('float')\n",
    "    return df\n",
    "\n",
    "def mlp_fill_MAR_blanks(df):\n",
    "    #change true nulls to fit missingness definitions already in the dataset\n",
    "    df.isnull().sum()\n",
    "    df.MAR_P = df.MAR_P.fillna(value='U')\n",
    "    df.DMAR = df.DMAR.fillna(value=9)\n",
    "    df.DMAR.replace('',9, inplace=True) # need to take care of 1 vs '1'\n",
    "#     df.DMAR.replace('1',1, inplace=True)\n",
    "#     df.DMAR.replace('2',2, inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_FRACE(df):\n",
    "    #combine FRACEHISP unknowns columns\n",
    "    df.FRACEHISP = df.FRACEHISP.replace(8,9)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_X_NA(df):\n",
    "    #assign 'X' to 'N' for RF_FEDRG RF_ARTEC and 'Y' for MAR_P since paternity assumed for married\n",
    "    for x in ['RF_FEDRG', 'RF_ARTEC']:\n",
    "        df[x].replace('X','N', inplace=True)\n",
    "    df.MAR_P.replace('X','Y', inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_ILs(df):\n",
    "    #assign 888 to mean for ILLB_R and ILP_R\n",
    "    for x in ['ILLB_R', 'ILP_R', 'ILOP_R']:\n",
    "        print(x)\n",
    "        df[x].replace(888,df.MAGER*12, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9nQrxegyVU3"
   },
   "outputs": [],
   "source": [
    "def measure_missing(df, target):\n",
    "    #create table of missingness proportions\n",
    "    missing_props = pd.DataFrame()\n",
    "    for i in range(0,len(missing_vals)):\n",
    "        temp = df.groupby(target)[missing_dict[list(missing_dict.keys())[i]]].apply\\\n",
    "        (lambda x: np.sum(x==missing_vals[i])/(df.shape[0]/2))\n",
    "        missing_props = pd.concat([missing_props, temp], axis=1)   \n",
    "\n",
    "    #create lists of variables with high missingness vs. low missingness\n",
    "    large_miss = list(missing_props.columns[missing_props.apply(lambda x: sum(x)>0.1, axis=0)])\n",
    "    small_miss = list(missing_props.columns[missing_props.apply(lambda x: sum(x)<0.1, axis=0)])\n",
    "\n",
    "    #sort low missingness categorical variables into types\n",
    "    small_cats = {'cat3': [], 'cat8': [], 'cat9': [], 'catU': []}\n",
    "\n",
    "    for var in small_miss:\n",
    "        if var in missing_dict['cat3']:\n",
    "            small_cats['cat3'].append(var) \n",
    "        elif var in missing_dict['cat8']:\n",
    "            small_cats['cat8'].append(var)\n",
    "        elif var in missing_dict['cat9']:\n",
    "            small_cats['cat9'].append(var)\n",
    "        elif var in missing_dict['catU']:\n",
    "            small_cats['catU'].append(var)    \n",
    "\n",
    "\n",
    "    #sort low missingness continuous variables\n",
    "    small_conts = {'cont9': [], 'cont99': [], 'cont999': [], 'cont99.9': []}\n",
    "\n",
    "    for var in small_miss:\n",
    "        if var in missing_dict['cont9']:\n",
    "            small_conts['cont9'].append(var) \n",
    "        elif var in missing_dict['cont99']:\n",
    "            small_conts['cont99'].append(var)\n",
    "        elif var in missing_dict['cont999']:\n",
    "            small_conts['cont999'].append(var)\n",
    "        elif var in missing_dict['cont99.9']:\n",
    "            small_conts['cont99.9'].append(var)\n",
    "    return small_conts, small_cats, large_miss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XkzHquDjyVU8"
   },
   "outputs": [],
   "source": [
    "def mlp_impute_s_cat(df,df_w,small_cats):\n",
    "    #mode imputation of categoricals with low missingness\n",
    "    small_vals = [3,8,9,'U']\n",
    "    for i in range(0, len(small_vals)):\n",
    "        temp_lis = small_cats[list(small_cats.keys())[i]]\n",
    "        for x in temp_lis:\n",
    "            major_cat = df_w[x].value_counts().sort_values(ascending=False).index[0]\n",
    "            df[x]=df[x].replace(small_vals[i],major_cat)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_s_num(df,df_w,small_conts):\n",
    "    #median imputation of categoricals with low missingness\n",
    "    #statistical significance of relationship with target imnproves on variable by variable basis after \n",
    "    #median imputation\n",
    "    csmall_vals = [9,99,999,99.9]\n",
    "    for i in range(0, len(csmall_vals)):\n",
    "        temp_lis = small_conts[list(small_conts.keys())[i]]\n",
    "        for x in temp_lis:\n",
    "            df[x]=df[x].replace(csmall_vals[i],df_w[x].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize9(x):\n",
    "    if x==9:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def binarize99(x):\n",
    "    if x==99:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def binarize999(x):\n",
    "    if x==999:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def mlp_impute_FAGECOMB(df,df_w):\n",
    "    #Impute FAGECOMB missing vals and store whether column was imputed    \n",
    "    df['FAGECOMB_IMP'] = df.FAGECOMB.apply(lambda x: binarize99(x))\n",
    "    df.FAGECOMB.replace(99, df_w.FAGECOMB.median(),inplace = True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_ILPs(df,df_w):\n",
    "    #Impute ILOP_R and ILP_R missing vals and store whether column was imputed\n",
    "    for x in ['ILOP_R', 'ILP_R']:\n",
    "        df[x+'_IMP'] = df[x].apply(lambda x: binarize999(x))\n",
    "    for x in ['ILOP_R', 'ILP_R']:\n",
    "        df[x].replace(999,df_w[x].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_FRACE_ED(df,df_w):\n",
    "    #Impute FRACEHISP and FEDUC missing vals and store whether column was imputed\n",
    "    for x in ['FRACEHISP', 'FEDUC']:\n",
    "        df[x+'_IMP'] = df[x].apply(lambda x: binarize9(x))\n",
    "    for x in ['FRACEHISP', 'FEDUC']:\n",
    "        df[x].replace(9,df_w[x].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_combine(df):\n",
    "    #Combine imputed flag columns into one\n",
    "    import re\n",
    "    imputed_col = list(filter(lambda i: re.search('_IMP',i), df.columns))\n",
    "    print(len(imputed_col))\n",
    "    if len(imputed_col)==0:\n",
    "        return df\n",
    "    df['lrg_miss_imp']= [1 if sum(df[imputed_col].iloc[i])>1 else 0 for i in range(len(df))]\n",
    "    df.drop(columns = imputed_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hK6Jaf6cyVVB"
   },
   "outputs": [],
   "source": [
    "def mlp_all_of_the_above(df,df_w,target):\n",
    "    df = mlp_fill_MAR_blanks(df)\n",
    "    df = mlp_reassign_FRACE(df)\n",
    "    df = mlp_reassign_X_NA(df)\n",
    "#     df = mlp_reassign_ILs(df)\n",
    "    df = mlp_convert_cont_floats(df)\n",
    "    small_conts, small_cats, large_miss = measure_missing(df,target)\n",
    "    df = mlp_impute_s_cat(df,df_w,small_cats)\n",
    "    df = mlp_impute_s_num(df,df_w,small_conts)\n",
    "    df = mlp_impute_FAGECOMB(df,df_w)\n",
    "    df = mlp_impute_ILPs(df,df_w)\n",
    "    df = mlp_impute_FRACE_ED(df,df_w)\n",
    "    df = mlp_convert_nom_cat(df)\n",
    "    df = mlp_convert_ord_cat(df)\n",
    "#     df = mlp_impute_combine(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StBbx-6XyVVF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Un5txndsyVVK"
   },
   "outputs": [],
   "source": [
    "#dummfiy columns\n",
    "\n",
    "def dummify_columns(dataframe,var_list):\n",
    "    '''\n",
    "    dummifies a columns, merges with the dataframe, and drops the non-dummified column\n",
    "    ------------\n",
    "    dataframe: full dataframe\n",
    "    variable: column name as string\n",
    "    '''\n",
    "    for vr in var_list:\n",
    "        dummified_feature = pd.get_dummies(dataframe[vr], prefix=vr,drop_first=True,prefix_sep='__')\n",
    "        dataframe = pd.concat([dataframe,dummified_feature],axis=1,sort=False)\n",
    "    dataframe.drop(columns = var_list, inplace = True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDRNwL_eyVVN"
   },
   "outputs": [],
   "source": [
    "def add_random_column_to_df (dataframe):\n",
    "    import random\n",
    "    mylist = []\n",
    "    for i in range(0,dataframe.shape[0]):\n",
    "        x = random.randint(1,1000)\n",
    "        mylist.append(x)\n",
    "    dataframe['RANDOM'] = mylist\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNFuZC4IyVVP"
   },
   "outputs": [],
   "source": [
    "#LabelEncoding Function. Thanks Ira!\n",
    "def LabelEncoding(dataframe):\n",
    "    '''\n",
    "    Function that takes a dataframe and transforms it with label encoding on all the categorical features.\n",
    "    '''\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    #create a list using object types since dataframe.dtypes.value_counts() only shows objects and int64\n",
    "    objlist = list(dataframe.select_dtypes(include=['object','category']).columns)\n",
    "    \n",
    "    #change type then transform column using cat codes\n",
    "    for col in objlist:\n",
    "        dataframe[col] = dataframe[col].astype('category')\n",
    "        dataframe[col] = dataframe[col].cat.codes\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMIML5cNyVVS"
   },
   "outputs": [],
   "source": [
    "# begin dictionary of columns to analyze for CCHD - includes pre-pregnancy and gestational features\n",
    "# features re: delivery and labor are not useful for this use case\n",
    "variables = {'nominal_categorical':['MBSTATE_REC','MRACEHISP','MAR_P','DMAR','MEDUC','FRACEHISP',\\\n",
    "                                    'FEDUC','WIC','RF_PDIAB','RF_GDIAB','RF_PHYPE','RF_GHYPE',\\\n",
    "                                    'RF_EHYPE','RF_PPTERM','RF_INFTR','RF_FEDRG','RF_ARTEC','RF_CESAR',\\\n",
    "                                  'IP_GON','IP_SYPH','IP_CHLAM','IP_HEPB','IP_HEPC', 'PAY', 'SEX'],\\\n",
    "           'ordinal_categorical':['PRECARE', 'DOB_MM'],\\\n",
    "           'continuous':['MAGER', 'FAGECOMB','PRIORTERM','PRIORLIVE','PRIORDEAD','LBO_REC','TBO_REC',\\\n",
    "                         'ILLB_R','ILOP_R','ILP_R','PREVIS','CIG_0','CIG_1','CIG_2','CIG_3','M_Ht_In','BMI',\\\n",
    "                         'WTGAIN','RF_CESARN','OEGest_Comb'],\\\n",
    "            'target':['CA_CCHD']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyiOqbNkyVVW"
   },
   "outputs": [],
   "source": [
    "#create missingness types:\n",
    "missing_dict = {'cont9': ['LBO_REC', 'TBO_REC'],\\\n",
    "                'cont99': ['FAGECOMB', 'PRIORTERM','PRIORLIVE', 'PRIORDEAD', 'PRECARE', 'PREVIS',\\\n",
    "                         'CIG_0', 'CIG_1', 'CIG_2', 'CIG_3', 'M_Ht_In', 'WTGAIN', 'RF_CESARN', 'OEGest_Comb'],\\\n",
    "                'cont999':['ILLB_R', 'ILP_R', 'ILOP_R'],\\\n",
    "                'cont99.9': ['BMI'],\\\n",
    "                'cat3': ['MBSTATE_REC'],\\\n",
    "                'cat8': ['MRACEHISP'],\\\n",
    "                'cat9': ['MEDUC', 'FEDUC', 'PAY', 'FRACEHISP', 'DMAR'],\\\n",
    "                'catU': ['WIC','RF_PDIAB','RF_GDIAB','RF_PHYPE',\\\n",
    "                        'RF_GHYPE','RF_EHYPE','RF_PPTERM','RF_INFTR','RF_FEDRG','RF_ARTEC','RF_CESAR','IP_GON',\\\n",
    "                        'IP_SYPH','IP_CHLAM','IP_HEPB','IP_HEPC', 'MAR_P']}\n",
    "missing_vals = [9,99,999,99.9,3,8,9,'U']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JP8Db6NCyVVZ"
   },
   "outputs": [],
   "source": [
    "#pull selected variables from 2016-2018 databases in SQL and append to a single dataframe\n",
    "query18 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc.us2018\"\n",
    "\n",
    "query17 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc.us2017\"\n",
    "\n",
    "query16 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc.us2016\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "CQlaCL_yyVVb",
    "outputId": "d4eaf122-095a-45fd-db63-21e7ab597d24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nqueries = [query18, query17, query16]\\n            \\ncchd = pd.DataFrame()\\ntest_cchd = pd.DataFrame()\\n\\nfor query in queries:\\n    temp = create_table_from_SQL('root','cdc',sql_pw, query)\\n    train, test = split_sets(temp, 0, test_prop=0.1)\\n    train = downsample_df(train, 'CA_CCHD')\\n    cchd = cchd.append(train)  \\n    test_cchd = test_cchd.append(test)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [query18, query17, query16]\n",
    "            \n",
    "cchd = pd.DataFrame()\n",
    "test_cchd = pd.DataFrame()\n",
    "\n",
    "for query in queries:\n",
    "    temp = create_table_from_SQL('root','cdc',sql_pw, query)\n",
    "    train, test = split_sets(temp, 0, test_prop=0.1)\n",
    "    train = downsample_df(train, 'CA_CCHD')\n",
    "    cchd = cchd.append(train)  \n",
    "    test_cchd = test_cchd.append(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfpYZde8yVVd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZapwVpAyVVr"
   },
   "outputs": [],
   "source": [
    "chd=cchd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7R4wqZQYyVVu"
   },
   "outputs": [],
   "source": [
    "chd_test = test_cchd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8pD8gHQyVVy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVP9Jhn6yVV1"
   },
   "outputs": [],
   "source": [
    "chd = mlp_all_of_the_above(chd,chd,'CA_CCHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfMNGHWyyVV4"
   },
   "outputs": [],
   "source": [
    "chd['lrg_miss_imp'] = chd.FAGECOMB_IMP | chd.FRACEHISP_IMP | chd.ILOP_R_IMP | chd.ILP_R_IMP | chd.FEDUC_IMP\n",
    "chd.drop(columns = ['FAGECOMB_IMP','FRACEHISP_IMP','ILOP_R_IMP','ILP_R_IMP','FEDUC_IMP'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CXMX73jyVV8"
   },
   "outputs": [],
   "source": [
    "chd = LabelEncoding(chd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEuHJwEbyVWA"
   },
   "outputs": [],
   "source": [
    "chd = add_random_column_to_df(chd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpB2O8sJyVWD"
   },
   "outputs": [],
   "source": [
    "target = 'CA_CCHD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tve8Wzh3yVWH"
   },
   "outputs": [],
   "source": [
    "chd_test = chd_test.loc[(chd_test[target]=='Y')|(chd_test[target]=='N'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXZt2B8GyVWL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chd_test = mlp_all_of_the_above(chd_test,chd,'CA_CCHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBgjmJ4vyVWO"
   },
   "outputs": [],
   "source": [
    "chd_test['lrg_miss_imp'] = chd_test.FAGECOMB_IMP | chd_test.FRACEHISP_IMP | chd_test.ILOP_R_IMP | chd_test.ILP_R_IMP | chd_test.FEDUC_IMP\n",
    "chd_test.drop(columns = ['FAGECOMB_IMP','FRACEHISP_IMP','ILOP_R_IMP','ILP_R_IMP','FEDUC_IMP'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nc7oZR3yVWS"
   },
   "outputs": [],
   "source": [
    "chd_test = LabelEncoding(chd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsUeB5RByVWW"
   },
   "outputs": [],
   "source": [
    "chd_test = add_random_column_to_df(chd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEr-Lkn6yVWZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5rzG_xNyVWc"
   },
   "outputs": [],
   "source": [
    "#PDIAB\n",
    "chd = chd[chd['RF_PDIAB'] == 1]\n",
    "chd_test = chd_test[chd_test['RF_PDIAB'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "s-mCfvq93o9P",
    "outputId": "90b2de73-a765-486a-c3c5-3ae778bb53d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MBSTATE_REC', 'MRACEHISP', 'MAR_P', 'DMAR', 'MEDUC', 'FRACEHISP',\n",
       "       'FEDUC', 'WIC', 'RF_PDIAB', 'RF_GDIAB', 'RF_PHYPE', 'RF_GHYPE',\n",
       "       'RF_EHYPE', 'RF_PPTERM', 'RF_INFTR', 'RF_FEDRG', 'RF_ARTEC', 'RF_CESAR',\n",
       "       'IP_GON', 'IP_SYPH', 'IP_CHLAM', 'IP_HEPB', 'IP_HEPC', 'PAY', 'SEX',\n",
       "       'PRECARE', 'DOB_MM', 'MAGER', 'FAGECOMB', 'PRIORTERM', 'PRIORLIVE',\n",
       "       'PRIORDEAD', 'LBO_REC', 'TBO_REC', 'ILLB_R', 'ILOP_R', 'ILP_R',\n",
       "       'PREVIS', 'CIG_0', 'CIG_1', 'CIG_2', 'CIG_3', 'M_Ht_In', 'BMI',\n",
       "       'WTGAIN', 'RF_CESARN', 'OEGest_Comb', 'CA_CCHD', 'lrg_miss_imp',\n",
       "       'RANDOM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zd4sLzUgyVWh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ke8ruYLyVWk"
   },
   "outputs": [],
   "source": [
    "#test train split\n",
    "target = 'CA_CCHD'\n",
    "X_train = chd.drop(target, axis=1)\n",
    "y_train = chd[target]\n",
    "\n",
    "X_test = chd_test.drop(target, axis=1)\n",
    "y_test = chd_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "B2XWfiSUyVWm",
    "outputId": "f0f4ca43-0d26-4d47-ec12-9b61393bfc66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.01173\n",
      "The test     error is: 0.51675\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST INITIAL FIT\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomForest = RandomForestClassifier(class_weight={0:1,1:1700})\n",
    "randomForest.set_params(random_state=0)\n",
    "randomForest.fit(X_train, y_train) \n",
    "print(\"The training error is: %.5f\" % (1 - randomForest.score(X_train, y_train)))\n",
    "print(\"The test     error is: %.5f\" % (1 - randomForest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "weuGpDEJyVWo",
    "outputId": "8f8dddf3-ded6-47e7-f89e-6ad4fec8a7e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.94 s, sys: 198 ms, total: 7.14 s\n",
      "Wall time: 3min 9s\n",
      "{'criterion': 'gini', 'max_depth': 14, 'n_estimators': 10}\n",
      "best score: 0.8268120086057001\n",
      "The training error is: 0.02933\n",
      "The test     error is: 0.53514\n",
      "         feature  importance\n",
      "0       FAGECOMB    0.069322\n",
      "1    OEGest_Comb    0.065725\n",
      "2            BMI    0.065715\n",
      "3          MAGER    0.064558\n",
      "4        M_Ht_In    0.059813\n",
      "5         RANDOM    0.057050\n",
      "6         PREVIS    0.049549\n",
      "7         ILLB_R    0.048171\n",
      "8          ILP_R    0.044247\n",
      "9         DOB_MM    0.042495\n",
      "10        WTGAIN    0.042077\n",
      "11        ILOP_R    0.033640\n",
      "12       LBO_REC    0.032270\n",
      "13         FEDUC    0.031792\n",
      "14           WIC    0.027660\n",
      "15         MEDUC    0.025211\n",
      "16     PRIORTERM    0.024708\n",
      "17   MBSTATE_REC    0.024568\n",
      "18       PRECARE    0.023314\n",
      "19     PRIORLIVE    0.018285\n",
      "20     RF_CESARN    0.017618\n",
      "21           PAY    0.017393\n",
      "22       TBO_REC    0.014789\n",
      "23      RF_PHYPE    0.013011\n",
      "24         CIG_3    0.011155\n",
      "25      RF_GHYPE    0.009174\n",
      "26          DMAR    0.008739\n",
      "27     PRIORDEAD    0.008215\n",
      "28        IP_GON    0.008133\n",
      "29  lrg_miss_imp    0.006965\n",
      "30         CIG_0    0.006687\n",
      "31           SEX    0.006182\n",
      "32         CIG_2    0.004526\n",
      "33         MAR_P    0.004308\n",
      "34      RF_INFTR    0.004252\n",
      "35     MRACEHISP    0.003283\n",
      "36         CIG_1    0.003029\n",
      "37       IP_HEPB    0.002351\n",
      "38     FRACEHISP    0.000010\n",
      "39      RF_CESAR    0.000009\n",
      "40     RF_PPTERM    0.000004\n",
      "41      RF_GDIAB    0.000000\n",
      "42      RF_EHYPE    0.000000\n",
      "43      RF_FEDRG    0.000000\n",
      "44       IP_SYPH    0.000000\n",
      "45       IP_HEPC    0.000000\n",
      "46      RF_PDIAB    0.000000\n",
      "47      IP_CHLAM    0.000000\n",
      "48      RF_ARTEC    0.000000\n",
      "CPU times: user 1.97 s, sys: 18.8 ms, total: 1.98 s\n",
      "Wall time: 1.99 s\n",
      "precision :  0.06372502003599163\n",
      "[[533809 614751]\n",
      " [   221    392]]\n"
     ]
    }
   ],
   "source": [
    "# set the parameter grid\n",
    "score_method = 'precision'\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "grid_para_forest = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 16),\n",
    "    'n_estimators': range(10, 70, 5)\n",
    "}\n",
    "\n",
    "# GRID SEARCH\n",
    "grid_search_forest = ms.GridSearchCV(randomForest, grid_para_forest, scoring=score_method, cv=10, n_jobs=-1,)\n",
    "%time grid_search_forest.fit(X_train, y_train)\n",
    "\n",
    "#Best Params and Score\n",
    "print(grid_search_forest.best_params_)\n",
    "print('best score:', grid_search_forest.best_score_)\n",
    "\n",
    "# get the training/test errors\n",
    "print(\"The training error is: %.5f\" % (1 - grid_search_forest.best_estimator_.score(X_train, y_train)))\n",
    "print(\"The test     error is: %.5f\" % (1 - grid_search_forest.best_estimator_.score(X_test, y_test)))\n",
    "\n",
    "#list of feature importance\n",
    "feature_importance = list(zip(X_train.columns, randomForest.feature_importances_))\n",
    "# dtype = [('feature', 'S10'), ('importance', 'float')]\n",
    "# feature_importance = np.array(feature_importance, dtype=dtype)\n",
    "# feature_sort = np.sort(feature_importance, order='importance')[::-1]\n",
    "\n",
    "#Sorting feature importance\n",
    "# sorted_features = pd.DataFrame(sorted(feature_importance, key=lambda x: x[1], reverse=True))\n",
    "sorted_features = pd.DataFrame((list(t) for t in feature_importance),columns = ['feature','importance']\n",
    "                              ).sort_values('importance',ascending = False).reset_index().drop(columns='index')\n",
    "print(sorted_features)\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%time cm = confusion_matrix(y_test, grid_search_forest.best_estimator_.predict(X_test))\n",
    "\n",
    "print(score_method, ': ', cm[1,1]/sum(cm[:,1])*100)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrKabr0ryVWt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3lf--rUyVWy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBPUPlMVyVW1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PDAIB_RF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
