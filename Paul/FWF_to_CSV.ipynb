{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_columns = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_dictionary(text_file):\n",
    "    '''\n",
    "    Takes text file from User Guide to create library identifying locations of each feature.\n",
    "    Returns pd.DataFrame\n",
    "    The 'length' feature appears to be inconsistent\n",
    "    '''\n",
    "\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    with open(text_file, 'r+') as f:\n",
    "        ug = f.readlines()\n",
    "\n",
    "    # Get field codes and corresponding columns\n",
    "    field_list = [\n",
    "        re.search(r'\\b[0-9-]+\\b\\s\\b[0-9]+\\b\\s\\b[A-Z0-9_]{2,}\\b',i).group() for i in ug if \n",
    "        re.search(r'\\b[0-9-]+\\b\\s\\b[0-9]+\\b\\s\\b[A-Z0-9_]{2,}\\b',i)\n",
    "    ]\n",
    "\n",
    "    # Place field numbers into DF\n",
    "    field_code = pd.DataFrame(columns = ['start','end','length','field'])\n",
    "    field_code['length'] = [re.split('\\s',i)[1] for i in field_list]\n",
    "    field_code['field'] = [re.split('\\s',i)[2] for i in field_list]\n",
    "    field_range = [re.split('\\s',i)[0] for i in field_list]\n",
    "    field_code['start'] = [re.split('-',i)[0] if re.search('-',i) else i for i in field_range]\n",
    "    field_code['end'] = [re.split('-',i)[1] if re.search('-',i) else i for i in field_range]\n",
    "\n",
    "    # Convert entry to numeric\n",
    "    for i in ['start','end','length']:\n",
    "        field_code[i] = pd.to_numeric(field_code[i])\n",
    "    \n",
    "    # Missing entries\n",
    "    field_code_ug2018 = pd.DataFrame([[165,165,1,'F_FEDUC'], [280,281,2,'M_Ht_In'], \n",
    "                                      [292,294,3,'PWgt_R'], [299,301,3,'DWgt_R'], \n",
    "                                      [328,328,1,'f_RF_INFT'], [499,500,2,'OEGest_Comb'], \n",
    "                                      [501,502,2,'OEGest_R10'], [503,503,1,'OEGest_R3']], \n",
    "                                     columns = ['start','end','length','field'])\n",
    "    \n",
    "    field_code_ug2017 = pd.DataFrame([[280, 281, 2, 'M_Ht_In'],[292, 294, 3, 'PWgt_R'],[299, 301, 3, 'DWgt_R'],\n",
    "                                      [328, 328, 1, 'f_RF_INFT'],[499, 500, 2, 'OEGest_Comb'],\n",
    "                                      [501, 502, 2, 'OEGest_R10'],[503, 503, 1, 'OEGest_R3']],\n",
    "                                     columns = ['start','end','length','field'])\n",
    "    \n",
    "    field_code_ug2016 = pd.DataFrame([[280, 281, 2, 'M_Ht_In'],[292, 294, 3, 'PWgt_R'],[299, 301, 3, 'DWgt_R'],\n",
    "                                      [328, 328, 1, 'f_RF_INFT'],[499, 500, 2, 'OEGest_Comb'],\n",
    "                                      [501, 502, 2, 'OEGest_R10'],[503, 503, 1, 'OEGest_R3']],\n",
    "                                     columns = ['start','end','length','field'])\n",
    "    \n",
    "    field_code_ug2008 = pd.DataFrame([[609, 609, 1, 'F_LD_AUGMENT']],\n",
    "                                     columns = ['start','end','length','field'])\n",
    "    \n",
    "\n",
    "\n",
    "    # Combine missing entries \n",
    "    if text_file.lower() == 'ug2018.txt':\n",
    "        field_code = field_code.append(field_code_ug2018,ignore_index= True,sort = 'start')\n",
    "        field_code = field_code.sort_values('start').reset_index().drop(columns='index')\n",
    "    elif text_file.lower() == 'ug2017.txt':\n",
    "        field_code = field_code.append(field_code_ug2017,ignore_index= True,sort = 'start')\n",
    "        field_code = field_code.sort_values('start').reset_index().drop(columns='index')\n",
    "    elif text_file.lower() == 'ug2016.txt':\n",
    "        field_code = field_code.append(field_code_ug2016,ignore_index= True,sort = 'start')\n",
    "        field_code = field_code.sort_values('start').reset_index().drop(columns='index')\n",
    "    elif text_file.lower() == 'ug2008.txt':\n",
    "        field_code = field_code.append(field_code_ug2008,ignore_index= True,sort = 'start')\n",
    "        field_code = field_code.sort_values('start').reset_index().drop(columns='index')\n",
    "\n",
    "    print(field_code.columns)\n",
    "    \n",
    "\n",
    "    # Find inconsistencies\n",
    "    for i in range(0,len(field_code)-1):\n",
    "        if field_code['end'][i] + 1 != field_code['start'][i+1]:\n",
    "            print('check after: ', i,  field_code['field'][i], field_code['start'][i], '-', field_code['end'][i])\n",
    "#         if field_code['end'][i] - field_code['start'][i] + 1 != field_code['length'][i]:\n",
    "#             print('check range for: ', i,  field_code['field'][i], field_code['start'][i], '-', \n",
    "#                   field_code['end'][i], field_code['length'][i])\n",
    "\n",
    "    \n",
    "\n",
    "    return field_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_more_filler(field_code):\n",
    "    '''\n",
    "    Looks for field that starts with 'FILLER' and drop the corresponding entry\n",
    "    Returns shorter library pd.DataFrame\n",
    "    '''\n",
    "    import re\n",
    "    \n",
    "    field_code = field_code.loc[[False if re.search('^FILLER',i) else True for i in field_code['field']]]\n",
    "    field_code.reset_index(inplace = True)\n",
    "    field_code.drop(columns = ['index'], inplace = True)\n",
    "    return field_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(text_file, csv_file, column_dictionary):\n",
    "    '''\n",
    "    Pass fwf text, destination csv, column dictionary\n",
    "    Read one line of the text file into python at a time\n",
    "    Break each row apart into list and write onto csv\n",
    "    '''\n",
    "\n",
    "    import csv\n",
    "    import time\n",
    "    import re\n",
    "    \n",
    "    start_at = time.time()\n",
    "    j=0\n",
    "    c_dict = column_dictionary\n",
    "    with open(csv_file,'w') as c:\n",
    "        wc = csv.writer(c,quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        # Write header\n",
    "        wc.writerow(list(c_dict['field']))\n",
    "\n",
    "        with open(text_file, 'r+') as f:\n",
    "            for line in f:\n",
    "\n",
    "#                 items = [\"\" if re.search(r'\\A\\s+\\Z',line[c_dict['start'][i]-1 : c_dict['end'][i]]) \n",
    "#                          else line[c_dict['start'][i]-1 : c_dict['end'][i]] \n",
    "#                          for i in range(0,len(c_dict))]\n",
    "                items = []\n",
    "                for i in range(0,len(c_dict)):\n",
    "#                     print(i)\n",
    "                    from_here = c_dict['start'][i]-1\n",
    "                    to_here = c_dict['end'][i]\n",
    "                    if re.search(r'\\A\\s+\\Z', line[from_here:to_here]):\n",
    "                        items += [\"\"]\n",
    "                    else:\n",
    "                        items += [line[from_here:to_here]]\n",
    "#                     print(from_here, to_here)\n",
    "\n",
    "                wc.writerow(items)\n",
    "#         keep track of progress\n",
    "                j += 1\n",
    "                if j>20:\n",
    "                    break\n",
    "#                 if j%10000 == 0:\n",
    "#                     print(j, time.time() - start_at)\n",
    "    print('done at',j, 'in', time.time() - start_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['end', 'field', 'length', 'start'], dtype='object')\n",
      "check after:  6 OCTERR 24 - 25\n",
      "check after:  7 FILLER 24 - 31\n",
      "check after:  20 MBCNTRY 80 - 81\n",
      "check after:  23 MRCNTRY 85 - 86\n",
      "check after:  24 FILLER 85 - 103\n",
      "check after:  26 RCNTY 91 - 93\n",
      "check after:  28 RCITY_POP 100 - 100\n",
      "Index(['end', 'field', 'length', 'start'], dtype='object')\n",
      "check after:  6 OCTERR 24 - 25\n",
      "check after:  7 FILLER 24 - 31\n",
      "check after:  20 MBCNTRY 80 - 81\n",
      "check after:  23 MRCNTRY 85 - 86\n",
      "check after:  24 FILLER 85 - 103\n",
      "check after:  26 RCNTY 91 - 93\n",
      "check after:  28 RCITY_POP 100 - 100\n",
      "Index(['end', 'field', 'length', 'start'], dtype='object')\n",
      "check after:  6 OCTERR 24 - 25\n",
      "check after:  7 FILLER 24 - 31\n",
      "check after:  20 FILLER 80 - 83\n",
      "check after:  21 MBCNTRY 80 - 81\n",
      "check after:  23 MRCNTRY 85 - 86\n",
      "check after:  24 FILLER 85 - 103\n",
      "check after:  26 RCNTY 91 - 93\n",
      "check after:  28 RCITY_POP 100 - 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pol\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>length_6</th>\n",
       "      <th>length_7</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FBRACE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>F_FEDUC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>MHISPX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>FHISPX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       field  length_6  length_7  length\n",
       "44    FBRACE       1.0       NaN     NaN\n",
       "236  F_FEDUC       NaN       1.0     1.0\n",
       "237   MHISPX       NaN       NaN     1.0\n",
       "238   FHISPX       NaN       NaN     1.0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check similarities/differences between data structure for 2016-2018\n",
    "u6 = create_column_dictionary('UG2016.txt')\n",
    "u6 = no_more_filler(u6)\n",
    "u7 = create_column_dictionary('UG2017.txt')\n",
    "u7 = no_more_filler(u7)\n",
    "u8 = create_column_dictionary('UG2018.txt')\n",
    "u8 = no_more_filler(u8)\n",
    "everything = pd.merge(pd.merge(u6,u7,how = 'outer', on = 'field', suffixes = ('_6','_7')),u8,how = 'outer', on = 'field')\n",
    "everything['check'] = [everything['length_7'][i]==everything['length_6'][i]==everything['length'][i] for i in range(len(everything))]\n",
    "everything[['field','length_6','length_7','length']][everything['check'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "non_reporting_col = list(filter(lambda i: re.search('\\AF_',i), u8.field))\n",
    "\n",
    "impute_flag_col = list(set(list(filter(lambda i: re.search('IMP',i), u8.field)) + ['LMPUSED'] \n",
    "                           + list(filter(lambda i: re.search('FLG',i), u8.field))))\n",
    "\n",
    "no_col = list(filter(lambda i: re.search('\\ANO_',i), u8.field))\n",
    "\n",
    "terr_col = ['OCTERR','OCNTYFIPS','OCNTYPOP','MBCNTRY','MRCNTRY','MRTERR','RCNTY','RCNTY_POP','RCITY_POP','RECTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find relationship between entries flagged as 'non-reporting'\n",
    "import re\n",
    "\n",
    "non_reporting = qwer[(qwer.iloc[:,[True if re.search('\\AF_',i) else False for i in qwer.columns]]==0).all(axis=1)]\n",
    "\n",
    "print(non_reporting[non_reporting_col].sum())\n",
    "\n",
    "for i in non_reporting.columns:\n",
    "    if non_reporting[i].nunique() <2:\n",
    "        print(i, non_reporting[i].nunique())\n",
    "\n",
    "non_reporting.groupby('RESTATUS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find relationship between 'unkown or not not stated' values and wholely 'not reported' codes\n",
    "no_dict = {'NO_LBRDLV':'\\ALD_', 'NO_RISKS':'\\ARF_', 'NO_INFEC':'\\AIP_', 'NO_MMORB':'\\AMM_', \n",
    " 'NO_ABNORM':'\\AAB_', 'NO_CONGEN':'\\ACA_'}\n",
    "import re\n",
    "\n",
    "for k in no_dict.keys():\n",
    "    print(qwer[qwer[k]==9].groupby(list(filter(lambda i: re.search(no_dict[k],i), qwer.columns))).size())\n",
    "    for q in list(filter(lambda i: re.search(no_dict[k],i), qwer.columns)):\n",
    "        print(q, qwer[qwer[q]=='U'][k].unique())\n",
    "        \n",
    "print(qwer.groupby(['NO_RISKS','RF_INFTR','RF_FEDRG','RF_ARTEC']).size())\n",
    "print(qwer.groupby(['NO_LBRDLV','LD_INDL']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['end', 'field', 'length', 'start'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "u08 = create_column_dictionary('UG2008.txt')\n",
    "u08 = no_more_filler(u08)\n",
    "eights = pd.merge(u08,u8,how = 'outer', on = 'field', suffixes = ('_08','_18'))\n",
    "eights['check'] = [eights['length_08'][i]==eights['length_18'][i] for i in range(len(eights))]\n",
    "eights[['field','length_08','length_18']][eights['check']==False].sort_values('field')\n",
    "eight_non_match=eights[['field','length_08','length_18']][\n",
    "    eights['check']==False].sort_values('field').reset_index().drop(columns = ['index'])\n",
    "eight_non_match['split'] = [re.split('',i)[1:-1] for i in eight_non_match['field']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "only08 = eight_non_match.loc[eight_non_match['length_08']>0][['field']].reset_index().drop(columns = ['index'])\n",
    "only18 = pd.DataFrame(set(eight_non_match['field'])-set(only08.field)\n",
    "                      - set(non_reporting_col) - set(impute_flag_col)-set(['DMAR'])- set(terr_col) - set(no_col),\n",
    "                      columns=['field']).sort_values('field').reset_index().drop(columns = ['index'])\n",
    "only08['split'] = [list(set(re.split('',i)[1:-1])) for i in only08['field']]\n",
    "only18['split'] = [re.split('',i)[1:-1] for i in only18['field']]\n",
    "only18['possibly'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>split</th>\n",
       "      <th>possibly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APGAR10</td>\n",
       "      <td>[A, P, G, A, R, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APGAR10R</td>\n",
       "      <td>[A, P, G, A, R, 1, 0, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFED</td>\n",
       "      <td>[B, F, E, D]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMI</td>\n",
       "      <td>[B, M, I]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMI_R</td>\n",
       "      <td>[B, M, I, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA_DOWN</td>\n",
       "      <td>[C, A, _, D, O, W, N]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CIG0_R</td>\n",
       "      <td>[C, I, G, 0, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CIG1_R</td>\n",
       "      <td>[C, I, G, 1, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CIG2_R</td>\n",
       "      <td>[C, I, G, 2, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CIG3_R</td>\n",
       "      <td>[C, I, G, 3, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CIG_0</td>\n",
       "      <td>[C, I, G, _, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DOB_TT</td>\n",
       "      <td>[D, O, B, _, T, T]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DWgt_R</td>\n",
       "      <td>[D, W, g, t, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FEDUC</td>\n",
       "      <td>[F, E, D, U, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FHISPX</td>\n",
       "      <td>[F, H, I, S, P, X]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FHISP_R</td>\n",
       "      <td>[F, H, I, S, P, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FRACE15</td>\n",
       "      <td>[F, R, A, C, E, 1, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FRACE31</td>\n",
       "      <td>[F, R, A, C, E, 3, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FRACE6</td>\n",
       "      <td>[F, R, A, C, E, 6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>F_FEDUC</td>\n",
       "      <td>[F, _, F, E, D, U, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ILIVE</td>\n",
       "      <td>[I, L, I, V, E]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ILLB_R</td>\n",
       "      <td>[I, L, L, B, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ILLB_R11</td>\n",
       "      <td>[I, L, L, B, _, R, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ILOP_R</td>\n",
       "      <td>[I, L, O, P, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ILOP_R11</td>\n",
       "      <td>[I, L, O, P, _, R, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ILP_R</td>\n",
       "      <td>[I, L, P, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ILP_R11</td>\n",
       "      <td>[I, L, P, _, R, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IP_CHLAM</td>\n",
       "      <td>[I, P, _, C, H, L, A, M]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IP_GON</td>\n",
       "      <td>[I, P, _, G, O, N]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>IP_HEPB</td>\n",
       "      <td>[I, P, _, H, E, P, B]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>IP_HEPC</td>\n",
       "      <td>[I, P, _, H, E, P, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IP_SYPH</td>\n",
       "      <td>[I, P, _, S, Y, P, H]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ITRAN</td>\n",
       "      <td>[I, T, R, A, N]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LD_ANTB</td>\n",
       "      <td>[L, D, _, A, N, T, B]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MAR_P</td>\n",
       "      <td>[M, A, R, _, P]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MBSTATE_REC</td>\n",
       "      <td>[M, B, S, T, A, T, E, _, R, E, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MHISPX</td>\n",
       "      <td>[M, H, I, S, P, X]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MHISP_R</td>\n",
       "      <td>[M, H, I, S, P, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MM_AICU</td>\n",
       "      <td>[M, M, _, A, I, C, U]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MM_MTR</td>\n",
       "      <td>[M, M, _, M, T, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MM_PLAC</td>\n",
       "      <td>[M, M, _, P, L, A, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MM_RUPT</td>\n",
       "      <td>[M, M, _, R, U, P, T]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>MM_UHYST</td>\n",
       "      <td>[M, M, _, U, H, Y, S, T]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MRACE15</td>\n",
       "      <td>[M, R, A, C, E, 1, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>MRACE31</td>\n",
       "      <td>[M, R, A, C, E, 3, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>MRACE6</td>\n",
       "      <td>[M, R, A, C, E, 6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MTRAN</td>\n",
       "      <td>[M, T, R, A, N]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>M_Ht_In</td>\n",
       "      <td>[M, _, H, t, _, I, n]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>OB_ECVF</td>\n",
       "      <td>[O, B, _, E, C, V, F]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>OB_ECVS</td>\n",
       "      <td>[O, B, _, E, C, V, S]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>OEGest_Comb</td>\n",
       "      <td>[O, E, G, e, s, t, _, C, o, m, b]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>OEGest_R10</td>\n",
       "      <td>[O, E, G, e, s, t, _, R, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>OEGest_R3</td>\n",
       "      <td>[O, E, G, e, s, t, _, R, 3]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PAY</td>\n",
       "      <td>[P, A, Y]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PAY_REC</td>\n",
       "      <td>[P, A, Y, _, R, E, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PRECARE5</td>\n",
       "      <td>[P, R, E, C, A, R, E, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PREVIS</td>\n",
       "      <td>[P, R, E, V, I, S]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PRIORDEAD</td>\n",
       "      <td>[P, R, I, O, R, D, E, A, D]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>PRIORLIVE</td>\n",
       "      <td>[P, R, I, O, R, L, I, V, E]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PRIORTERM</td>\n",
       "      <td>[P, R, I, O, R, T, E, R, M]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>PWgt_R</td>\n",
       "      <td>[P, W, g, t, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>RF_ARTEC</td>\n",
       "      <td>[R, F, _, A, R, T, E, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RF_EHYPE</td>\n",
       "      <td>[R, F, _, E, H, Y, P, E]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RF_FEDRG</td>\n",
       "      <td>[R, F, _, F, E, D, R, G]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>RF_GDIAB</td>\n",
       "      <td>[R, F, _, G, D, I, A, B]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>RF_GHYPE</td>\n",
       "      <td>[R, F, _, G, H, Y, P, E]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RF_INFTR</td>\n",
       "      <td>[R, F, _, I, N, F, T, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RF_PDIAB</td>\n",
       "      <td>[R, F, _, P, D, I, A, B]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>RF_PHYPE</td>\n",
       "      <td>[R, F, _, P, H, Y, P, E]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SETORDER_R</td>\n",
       "      <td>[S, E, T, O, R, D, E, R, _, R]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>WIC</td>\n",
       "      <td>[W, I, C]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>f_RF_INFT</td>\n",
       "      <td>[f, _, R, F, _, I, N, F, T]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          field                              split  possibly\n",
       "0       APGAR10              [A, P, G, A, R, 1, 0]         0\n",
       "1      APGAR10R           [A, P, G, A, R, 1, 0, R]         0\n",
       "2          BFED                       [B, F, E, D]         0\n",
       "3           BMI                          [B, M, I]         0\n",
       "4         BMI_R                    [B, M, I, _, R]         0\n",
       "5       CA_DOWN              [C, A, _, D, O, W, N]         0\n",
       "6        CIG0_R                 [C, I, G, 0, _, R]         0\n",
       "7        CIG1_R                 [C, I, G, 1, _, R]         0\n",
       "8        CIG2_R                 [C, I, G, 2, _, R]         0\n",
       "9        CIG3_R                 [C, I, G, 3, _, R]         0\n",
       "10        CIG_0                    [C, I, G, _, 0]         0\n",
       "11       DOB_TT                 [D, O, B, _, T, T]         0\n",
       "12       DWgt_R                 [D, W, g, t, _, R]         0\n",
       "13        FEDUC                    [F, E, D, U, C]         0\n",
       "14       FHISPX                 [F, H, I, S, P, X]         0\n",
       "15      FHISP_R              [F, H, I, S, P, _, R]         0\n",
       "16      FRACE15              [F, R, A, C, E, 1, 5]         0\n",
       "17      FRACE31              [F, R, A, C, E, 3, 1]         0\n",
       "18       FRACE6                 [F, R, A, C, E, 6]         0\n",
       "19      F_FEDUC              [F, _, F, E, D, U, C]         0\n",
       "20        ILIVE                    [I, L, I, V, E]         0\n",
       "21       ILLB_R                 [I, L, L, B, _, R]         0\n",
       "22     ILLB_R11           [I, L, L, B, _, R, 1, 1]         0\n",
       "23       ILOP_R                 [I, L, O, P, _, R]         0\n",
       "24     ILOP_R11           [I, L, O, P, _, R, 1, 1]         0\n",
       "25        ILP_R                    [I, L, P, _, R]         0\n",
       "26      ILP_R11              [I, L, P, _, R, 1, 1]         0\n",
       "27     IP_CHLAM           [I, P, _, C, H, L, A, M]         0\n",
       "28       IP_GON                 [I, P, _, G, O, N]         0\n",
       "29      IP_HEPB              [I, P, _, H, E, P, B]         0\n",
       "30      IP_HEPC              [I, P, _, H, E, P, C]         0\n",
       "31      IP_SYPH              [I, P, _, S, Y, P, H]         0\n",
       "32        ITRAN                    [I, T, R, A, N]         0\n",
       "33      LD_ANTB              [L, D, _, A, N, T, B]         0\n",
       "34        MAR_P                    [M, A, R, _, P]         0\n",
       "35  MBSTATE_REC  [M, B, S, T, A, T, E, _, R, E, C]         0\n",
       "36       MHISPX                 [M, H, I, S, P, X]         0\n",
       "37      MHISP_R              [M, H, I, S, P, _, R]         0\n",
       "38      MM_AICU              [M, M, _, A, I, C, U]         0\n",
       "39       MM_MTR                 [M, M, _, M, T, R]         0\n",
       "40      MM_PLAC              [M, M, _, P, L, A, C]         0\n",
       "41      MM_RUPT              [M, M, _, R, U, P, T]         0\n",
       "42     MM_UHYST           [M, M, _, U, H, Y, S, T]         0\n",
       "43      MRACE15              [M, R, A, C, E, 1, 5]         0\n",
       "44      MRACE31              [M, R, A, C, E, 3, 1]         0\n",
       "45       MRACE6                 [M, R, A, C, E, 6]         0\n",
       "46        MTRAN                    [M, T, R, A, N]         0\n",
       "47      M_Ht_In              [M, _, H, t, _, I, n]         0\n",
       "48      OB_ECVF              [O, B, _, E, C, V, F]         0\n",
       "49      OB_ECVS              [O, B, _, E, C, V, S]         0\n",
       "50  OEGest_Comb  [O, E, G, e, s, t, _, C, o, m, b]         0\n",
       "51   OEGest_R10     [O, E, G, e, s, t, _, R, 1, 0]         0\n",
       "52    OEGest_R3        [O, E, G, e, s, t, _, R, 3]         0\n",
       "53          PAY                          [P, A, Y]         0\n",
       "54      PAY_REC              [P, A, Y, _, R, E, C]         0\n",
       "55     PRECARE5           [P, R, E, C, A, R, E, 5]         0\n",
       "56       PREVIS                 [P, R, E, V, I, S]         0\n",
       "57    PRIORDEAD        [P, R, I, O, R, D, E, A, D]         0\n",
       "58    PRIORLIVE        [P, R, I, O, R, L, I, V, E]         0\n",
       "59    PRIORTERM        [P, R, I, O, R, T, E, R, M]         0\n",
       "60       PWgt_R                 [P, W, g, t, _, R]         0\n",
       "61     RF_ARTEC           [R, F, _, A, R, T, E, C]         0\n",
       "62     RF_EHYPE           [R, F, _, E, H, Y, P, E]         0\n",
       "63     RF_FEDRG           [R, F, _, F, E, D, R, G]         0\n",
       "64     RF_GDIAB           [R, F, _, G, D, I, A, B]         0\n",
       "65     RF_GHYPE           [R, F, _, G, H, Y, P, E]         0\n",
       "66     RF_INFTR           [R, F, _, I, N, F, T, R]         0\n",
       "67     RF_PDIAB           [R, F, _, P, D, I, A, B]         0\n",
       "68     RF_PHYPE           [R, F, _, P, H, Y, P, E]         0\n",
       "69   SETORDER_R     [S, E, T, O, R, D, E, R, _, R]         0\n",
       "70          WIC                          [W, I, C]         0\n",
       "71    f_RF_INFT        [f, _, R, F, _, I, N, F, T]         0"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('CA_DOWNS', 0.875), ('F_UCA_DOWNS', 0.7), ('UCA_DOWNS', 0.7777777777777778)])\n",
      "this ['F_UCA_DOWNS', 'UCA_DOWNS', 'CA_DOWNS']\n",
      "dict_items([('UFHISP', 0.7142857142857143)])\n",
      "this ['UFHISP']\n",
      "dict_items([('FRACE', 0.7142857142857143), ('FRACEREC', 0.7142857142857143)])\n",
      "this ['FRACE', 'FRACEREC']\n",
      "dict_items([('FRACE', 0.7142857142857143), ('FRACEREC', 0.7142857142857143)])\n",
      "this ['FRACE', 'FRACEREC']\n",
      "dict_items([('FBRACE', 0.7142857142857143), ('FRACE', 0.8333333333333334), ('FRACEREC', 0.8333333333333334)])\n",
      "this ['FBRACE', 'FRACE', 'FRACEREC']\n",
      "dict_items([('ON_PROL', 0.7142857142857143)])\n",
      "this ['ON_PROL']\n",
      "dict_items([('F_LD_ANTIBIO', 0.7), ('LD_ANTI', 0.75)])\n",
      "this ['F_LD_ANTIBIO', 'LD_ANTI']\n",
      "dict_items([('UMHISP', 0.7142857142857143)])\n",
      "this ['UMHISP']\n",
      "dict_items([('MRACE', 0.7142857142857143), ('MRACEREC', 0.7142857142857143)])\n",
      "this ['MRACE', 'MRACEREC']\n",
      "dict_items([('MRACE', 0.7142857142857143), ('MRACEREC', 0.7142857142857143)])\n",
      "this ['MRACE', 'MRACEREC']\n",
      "dict_items([('MBRACE', 0.7142857142857143), ('MRACE', 0.8333333333333334), ('MRACEREC', 0.8333333333333334)])\n",
      "this ['MBRACE', 'MRACE', 'MRACEREC']\n",
      "dict_items([('F_OB_CERVIC', 0.7777777777777778), ('OP_ECVF', 0.75)])\n",
      "this ['OP_ECVF', 'F_OB_CERVIC']\n",
      "dict_items([('OP_ECVS', 0.75)])\n",
      "this ['OP_ECVS']\n",
      "dict_items([('PRECARE_REC', 0.8571428571428571)])\n",
      "this ['PRECARE_REC']\n",
      "dict_items([('UPREVIS', 0.8571428571428571)])\n",
      "this ['UPREVIS']\n",
      "dict_items([('F_URF_CHYPER', 0.7), ('F_URF_PHYPER', 0.7777777777777778), ('RF_PHYP', 0.75), ('URF_CHYPER', 0.7), ('URF_PHYPER', 0.7777777777777778)])\n",
      "this ['F_URF_CHYPER', 'URF_CHYPER', 'RF_PHYP', 'F_URF_PHYPER', 'URF_PHYPER']\n",
      "dict_items([('RF_DIAB', 0.875), ('URF_DIAB', 0.7777777777777778)])\n",
      "this ['URF_DIAB', 'RF_DIAB']\n",
      "dict_items([('F_URF_CHYPER', 0.7), ('F_URF_PHYPER', 0.7777777777777778), ('RF_GHYP', 0.875), ('RF_PHYP', 0.75), ('URF_CHYPER', 0.7), ('URF_PHYPER', 0.7777777777777778)])\n",
      "this ['F_URF_CHYPER', 'URF_CHYPER', 'RF_PHYP', 'F_URF_PHYPER', 'URF_PHYPER', 'RF_GHYP']\n",
      "dict_items([('RF_DIAB', 0.875), ('URF_DIAB', 0.7777777777777778)])\n",
      "this ['URF_DIAB', 'RF_DIAB']\n",
      "dict_items([('F_URF_CHYPER', 0.7), ('F_URF_PHYPER', 0.7777777777777778), ('RF_PHYP', 0.75), ('URF_CHYPER', 0.7), ('URF_PHYPER', 0.7777777777777778)])\n",
      "this ['F_URF_CHYPER', 'URF_CHYPER', 'RF_PHYP', 'F_URF_PHYPER', 'URF_PHYPER']\n"
     ]
    }
   ],
   "source": [
    "qaz = [[]]\n",
    "for j in range(len(only18['field'])):\n",
    "#     print(j)\n",
    "    temp_list = dict()\n",
    "    for i in range(len(only08)):\n",
    "#         print(i)\n",
    "        t_sum = sum([re.search(l,only18['field'][j]) != None for l in only08['split'][i]])\n",
    "        t_den = len(only18['field'][j]) + len(only08['split'][i]) - sum(\n",
    "            [re.search(l,only18['field'][j]) != None for l in only08['split'][i]])\n",
    "#         print(t_sum/t_den)\n",
    "        if t_sum/t_den >= 0.7:\n",
    "            temp_list[only08['field'][i]] = t_sum/t_den\n",
    "\n",
    "    if len(temp_list.keys())>0:\n",
    "        print(temp_list.items())\n",
    "        print('this', sorted(temp_list.keys(),key = temp_list.get))\n",
    "        qaz += [[j]+sorted(temp_list.keys(),key = temp_list.get)]\n",
    "\n",
    "# only18.drop(columns='split',inplace = True)\n",
    "\n",
    "        \n",
    "# only18['possibly']=[\n",
    "#     [only08['field'][i],sum([re.search(l,only18['field'][j]) != None \n",
    "#                               for l in only08['split'][i]])/(len(only08['split'][i])+len(only18['split'][j])\n",
    "#                                                              -sum([re.search(l,only18['field'][j]) != None \n",
    "#                                                                    for l in only08['split'][i]]))\n",
    "#  for i in range(len(only08)) if sum([re.search(l,only18['field'][j]) != None \n",
    "#                                      for l in only08['split'][i]])/len(only08['split'][i])>0.7]\n",
    "# for j in range(len(only18))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [5, 'F_UCA_DOWNS', 'UCA_DOWNS', 'CA_DOWNS'],\n",
       " [14, 'UFHISP'],\n",
       " [16, 'FRACE', 'FRACEREC'],\n",
       " [17, 'FRACE', 'FRACEREC'],\n",
       " [18, 'FBRACE', 'FRACE', 'FRACEREC'],\n",
       " [22, 'ON_PROL'],\n",
       " [32, 'F_LD_ANTIBIO', 'LD_ANTI'],\n",
       " [35, 'UMHISP'],\n",
       " [42, 'MRACE', 'MRACEREC'],\n",
       " [43, 'MRACE', 'MRACEREC'],\n",
       " [44, 'MBRACE', 'MRACE', 'MRACEREC'],\n",
       " [47, 'OP_ECVF', 'F_OB_CERVIC'],\n",
       " [48, 'OP_ECVS'],\n",
       " [53, 'PRECARE_REC'],\n",
       " [55, 'UPREVIS'],\n",
       " [61, 'F_URF_CHYPER', 'URF_CHYPER', 'RF_PHYP', 'F_URF_PHYPER', 'URF_PHYPER'],\n",
       " [63, 'URF_DIAB', 'RF_DIAB'],\n",
       " [64,\n",
       "  'F_URF_CHYPER',\n",
       "  'URF_CHYPER',\n",
       "  'RF_PHYP',\n",
       "  'F_URF_PHYPER',\n",
       "  'URF_PHYPER',\n",
       "  'RF_GHYP'],\n",
       " [66, 'URF_DIAB', 'RF_DIAB'],\n",
       " [67, 'F_URF_CHYPER', 'URF_CHYPER', 'RF_PHYP', 'F_URF_PHYPER', 'URF_PHYPER']]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
