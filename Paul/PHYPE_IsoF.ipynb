{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvSMILTUp-0E"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_columns = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run simple SQL query from python\n",
    "def create_table_from_SQL(user, database, password, query):\n",
    "    '''\n",
    "    - A function that returns a pandas dataframe from a SQL query in python\n",
    "    ---------------\n",
    "    - user: user for your local SQL connection in string format\n",
    "    - database: schema name where your database is stored in string format\n",
    "    - password: password to access your local SQL connection in string format\n",
    "    - query: SQL query in string format; enclose with double quotes and use single quotes\n",
    "    to designate VARCHAR values within queries; use schema_name.table_name after FROM statement\n",
    "    '''\n",
    "    import mysql.connector\n",
    "    cnx = mysql.connector.connect(user=user, database=database, password=password)\n",
    "    cursor = cnx.cursor()\n",
    "    query = query\n",
    "    cursor.execute(query)\n",
    "    df = pd.DataFrame(cursor.fetchall())\n",
    "    df.columns = cursor.column_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified version of Bettina's function which creates downsampled dataset for specific defects\n",
    "#vs overall NICU admissions\n",
    "\n",
    "def downsample_df (df, variable):\n",
    "\n",
    "    '''\n",
    "    Remove undefined information on defect presence admissions (defect == 'U'),\n",
    "    create a binary target vector, and create a \"balanced\" dataframe\n",
    "    with all defect cases and matching numbers of randomly selected non-defect cases.\n",
    "    --------------------\n",
    "    df: full dataframe\n",
    "    variable: variable or defect of interest in string format\n",
    "    '''\n",
    "\n",
    "    # remove unknown class from df\n",
    "    df_no_unknown = df[df[variable].isin(['Y', 'N'])]\n",
    "\n",
    "    # Create binary target vector, NICU = yes classified as class 0\n",
    "    df_y_n = pd.DataFrame(np.where((df_no_unknown[variable] == 'Y'), 0, 1))\n",
    "\n",
    "    # Get indicies of each class' observations\n",
    "    index_class0 = np.where(df_y_n == 0)[0]\n",
    "    index_class1 = np.where(df_y_n == 1)[0]\n",
    "\n",
    "    # Get numbers of observations in class 0\n",
    "    n_class0 = len(index_class0)\n",
    "\n",
    "    # Randomly sample the same number of observations from class 1 as in class 0, without replacement\n",
    "    np.random.seed(0)\n",
    "    index_class1_downsampled = np.random.choice(index_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Create dataframes for NICU and downsampled non-NICU\n",
    "    df_defect = df_no_unknown.iloc[index_class0]\n",
    "    df_adj_NONdefect = df_no_unknown.iloc[index_class1_downsampled]\n",
    "\n",
    "    # Append into 1 dataframe\n",
    "    df_downsampled = df_defect.append(df_adj_NONdefect)\n",
    "\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split out holdout test set\n",
    "def split_sets(dataframe, seed, test_prop=0.1): \n",
    "    '''\n",
    "    - A function that splits specifically a dataframe into a train and test portion\n",
    "    - Requires multiple assignment: train, test\n",
    "    ---------------\n",
    "    - dataframe: dataframe to be split\n",
    "    - seed: set seed for reproducability\n",
    "    - test_prop: takes a float - proportion of dataframe that should be allocated to the test set\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    testIdxes = np.random.choice(range(0,dataframe.shape[0]), size=round(dataframe.shape[0]*test_prop), replace=False)\n",
    "    trainIdxes = list(set(range(0,dataframe.shape[0])) - set(testIdxes))\n",
    "\n",
    "    train = dataframe.iloc[trainIdxes,:]\n",
    "    test  = dataframe.iloc[testIdxes,:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0_uluTpqo3C"
   },
   "outputs": [],
   "source": [
    "def mlp_convert_cont_floats(df):\n",
    "    #convert continuous variables to float\n",
    "    #update to split out ordinal categorical separately\n",
    "    for x in variables['continuous']:\n",
    "        df[x]=df[x].astype('float')\n",
    "    return df\n",
    "\n",
    "def mlp_convert_nom_cat(df):\n",
    "    #convert nominal categorical variables to category\n",
    "    for x in variables['nominal_categorical']:\n",
    "        df[x]=df[x].astype('category')\n",
    "    return df\n",
    "\n",
    "def mlp_convert_ord_cat(df):\n",
    "    #convert ordinal categorical variables\n",
    "    df.DOB_MM = df.DOB_MM.astype('category')\n",
    "    df.PRECARE = df.PRECARE.astype('float')\n",
    "    return df\n",
    "\n",
    "def mlp_fill_MAR_blanks(df):\n",
    "    #change true nulls to fit missingness definitions already in the dataset\n",
    "    df.isnull().sum()\n",
    "    df.MAR_P = df.MAR_P.fillna(value='U')\n",
    "    df.DMAR = df.DMAR.fillna(value=9)\n",
    "    df.DMAR.replace('',9, inplace=True) # need to take care of 1 vs '1'\n",
    "#     df.DMAR.replace('1',1, inplace=True)\n",
    "#     df.DMAR.replace('2',2, inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_FRACE(df):\n",
    "    #combine FRACEHISP unknowns columns\n",
    "    df.FRACEHISP = df.FRACEHISP.replace(8,9)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_X_NA(df):\n",
    "    #assign 'X' to 'N' for RF_FEDRG RF_ARTEC and 'Y' for MAR_P since paternity assumed for married\n",
    "    for x in ['RF_FEDRG', 'RF_ARTEC']:\n",
    "        df[x].replace('X','N', inplace=True)\n",
    "    df.MAR_P.replace('X','Y', inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_ILs(df):\n",
    "    #assign 888 to mean for ILLB_R and ILP_R\n",
    "    for x in ['ILLB_R', 'ILP_R', 'ILOP_R']:\n",
    "        print(x)\n",
    "        df[x].replace(888,df.MAGER*12, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyzSIR26RvN0"
   },
   "outputs": [],
   "source": [
    "def measure_missing(df, target):\n",
    "    #create table of missingness proportions\n",
    "    missing_props = pd.DataFrame()\n",
    "    for i in range(0,len(missing_vals)):\n",
    "        temp = df.groupby(target)[missing_dict[list(missing_dict.keys())[i]]].apply\\\n",
    "        (lambda x: np.sum(x==missing_vals[i])/(df.shape[0]/2))\n",
    "        missing_props = pd.concat([missing_props, temp], axis=1)   \n",
    "\n",
    "    #create lists of variables with high missingness vs. low missingness\n",
    "    large_miss = list(missing_props.columns[missing_props.apply(lambda x: sum(x)>0.1, axis=0)])\n",
    "    small_miss = list(missing_props.columns[missing_props.apply(lambda x: sum(x)<0.1, axis=0)])\n",
    "\n",
    "    #sort low missingness categorical variables into types\n",
    "    small_cats = {'cat3': [], 'cat8': [], 'cat9': [], 'catU': []}\n",
    "\n",
    "    for var in small_miss:\n",
    "        if var in missing_dict['cat3']:\n",
    "            small_cats['cat3'].append(var) \n",
    "        elif var in missing_dict['cat8']:\n",
    "            small_cats['cat8'].append(var)\n",
    "        elif var in missing_dict['cat9']:\n",
    "            small_cats['cat9'].append(var)\n",
    "        elif var in missing_dict['catU']:\n",
    "            small_cats['catU'].append(var)    \n",
    "\n",
    "\n",
    "    #sort low missingness continuous variables\n",
    "    small_conts = {'cont9': [], 'cont99': [], 'cont999': [], 'cont99.9': []}\n",
    "\n",
    "    for var in small_miss:\n",
    "        if var in missing_dict['cont9']:\n",
    "            small_conts['cont9'].append(var) \n",
    "        elif var in missing_dict['cont99']:\n",
    "            small_conts['cont99'].append(var)\n",
    "        elif var in missing_dict['cont999']:\n",
    "            small_conts['cont999'].append(var)\n",
    "        elif var in missing_dict['cont99.9']:\n",
    "            small_conts['cont99.9'].append(var)\n",
    "    return small_conts, small_cats, large_miss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIwGezHjRx1I"
   },
   "outputs": [],
   "source": [
    "def mlp_impute_s_cat(df,df_w,small_cats):\n",
    "    #mode imputation of categoricals with low missingness\n",
    "    small_vals = [3,8,9,'U']\n",
    "    for i in range(0, len(small_vals)):\n",
    "        temp_lis = small_cats[list(small_cats.keys())[i]]\n",
    "        for x in temp_lis:\n",
    "            major_cat = df_w[x].value_counts().sort_values(ascending=False).index[0]\n",
    "            df[x]=df[x].replace(small_vals[i],major_cat)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_s_num(df,df_w,small_conts):\n",
    "    #median imputation of categoricals with low missingness\n",
    "    #statistical significance of relationship with target imnproves on variable by variable basis after \n",
    "    #median imputation\n",
    "    csmall_vals = [9,99,999,99.9]\n",
    "    for i in range(0, len(csmall_vals)):\n",
    "        temp_lis = small_conts[list(small_conts.keys())[i]]\n",
    "        for x in temp_lis:\n",
    "            df[x]=df[x].replace(csmall_vals[i],df_w[x].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize9(x):\n",
    "    if x==9:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def binarize99(x):\n",
    "    if x==99:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def binarize999(x):\n",
    "    if x==999:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def mlp_impute_FAGECOMB(df,df_w):\n",
    "    #Impute FAGECOMB missing vals and store whether column was imputed    \n",
    "    df['FAGECOMB_IMP'] = df.FAGECOMB.apply(lambda x: binarize99(x))\n",
    "    df.FAGECOMB.replace(99, df_w.FAGECOMB.median(),inplace = True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_ILPs(df,df_w):\n",
    "    #Impute ILOP_R and ILP_R missing vals and store whether column was imputed\n",
    "    for x in ['ILOP_R', 'ILP_R']:\n",
    "        df[x+'_IMP'] = df[x].apply(lambda x: binarize999(x))\n",
    "    for x in ['ILOP_R', 'ILP_R']:\n",
    "        df[x].replace(999,df_w[x].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_FRACE_ED(df,df_w):\n",
    "    #Impute FRACEHISP and FEDUC missing vals and store whether column was imputed\n",
    "    for x in ['FRACEHISP', 'FEDUC']:\n",
    "        df[x+'_IMP'] = df[x].apply(lambda x: binarize9(x))\n",
    "    for x in ['FRACEHISP', 'FEDUC']:\n",
    "        df[x].replace(9,df_w[x].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_combine(df):\n",
    "    #Combine imputed flag columns into one\n",
    "    import re\n",
    "    imputed_col = list(filter(lambda i: re.search('_IMP',i), df.columns))\n",
    "    print(len(imputed_col))\n",
    "    if len(imputed_col)==0:\n",
    "        return df\n",
    "    df['lrg_miss_imp']= [1 if sum(df[imputed_col].iloc[i])>1 else 0 for i in range(len(df))]\n",
    "    df.drop(columns = imputed_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VODthm1R0Ok"
   },
   "outputs": [],
   "source": [
    "def mlp_all_of_the_above(df,df_w,target):\n",
    "    df = mlp_fill_MAR_blanks(df)\n",
    "    df = mlp_reassign_FRACE(df)\n",
    "    df = mlp_reassign_X_NA(df)\n",
    "#     df = mlp_reassign_ILs(df)\n",
    "    df = mlp_convert_cont_floats(df)\n",
    "    small_conts, small_cats, large_miss = measure_missing(df,target)\n",
    "    df = mlp_impute_s_cat(df,df_w,small_cats)\n",
    "    df = mlp_impute_s_num(df,df_w,small_conts)\n",
    "    df = mlp_impute_FAGECOMB(df,df_w)\n",
    "    df = mlp_impute_ILPs(df,df_w)\n",
    "    df = mlp_impute_FRACE_ED(df,df_w)\n",
    "    df = mlp_convert_nom_cat(df)\n",
    "    df = mlp_convert_ord_cat(df)\n",
    "#     df = mlp_impute_combine(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv3gFxjSR3eU"
   },
   "outputs": [],
   "source": [
    "#dummfiy columns\n",
    "\n",
    "def dummify_columns(dataframe,var_list):\n",
    "    '''\n",
    "    dummifies a columns, merges with the dataframe, and drops the non-dummified column\n",
    "    ------------\n",
    "    dataframe: full dataframe\n",
    "    variable: column name as string\n",
    "    '''\n",
    "    for vr in var_list:\n",
    "        dummified_feature = pd.get_dummies(dataframe[vr], prefix=vr,drop_first=True,prefix_sep='__')\n",
    "        dataframe = pd.concat([dataframe,dummified_feature],axis=1,sort=False)\n",
    "    dataframe.drop(columns = var_list, inplace = True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9GoeFnUR56r"
   },
   "outputs": [],
   "source": [
    "def add_random_column_to_df (dataframe):\n",
    "    import random\n",
    "    mylist = []\n",
    "    for i in range(0,dataframe.shape[0]):\n",
    "        x = random.randint(1,1000)\n",
    "        mylist.append(x)\n",
    "    dataframe['RANDOM'] = mylist\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wXMQ8tSR8Zc"
   },
   "outputs": [],
   "source": [
    "#LabelEncoding Function. Thanks Ira!\n",
    "def LabelEncoding(dataframe):\n",
    "    '''\n",
    "    Function that takes a dataframe and transforms it with label encoding on all the categorical features.\n",
    "    '''\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    #create a list using object types since dataframe.dtypes.value_counts() only shows objects and int64\n",
    "    objlist = list(dataframe.select_dtypes(include=['object','category']).columns)\n",
    "    \n",
    "    #change type then transform column using cat codes\n",
    "    for col in objlist:\n",
    "        dataframe[col] = dataframe[col].astype('category')\n",
    "        dataframe[col] = dataframe[col].cat.codes\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMrneiErR-pZ"
   },
   "outputs": [],
   "source": [
    "# begin dictionary of columns to analyze for CCHD - includes pre-pregnancy and gestational features\n",
    "# features re: delivery and labor are not useful for this use case\n",
    "variables = {'nominal_categorical':['MBSTATE_REC','MRACEHISP','MAR_P','DMAR','MEDUC','FRACEHISP',\\\n",
    "                                    'FEDUC','WIC','RF_PDIAB','RF_GDIAB','RF_PHYPE','RF_GHYPE',\\\n",
    "                                    'RF_EHYPE','RF_PPTERM','RF_INFTR','RF_FEDRG','RF_ARTEC','RF_CESAR',\\\n",
    "                                  'IP_GON','IP_SYPH','IP_CHLAM','IP_HEPB','IP_HEPC', 'PAY', 'SEX'],\\\n",
    "           'ordinal_categorical':['PRECARE', 'DOB_MM'],\\\n",
    "           'continuous':['MAGER', 'FAGECOMB','PRIORTERM','PRIORLIVE','PRIORDEAD','LBO_REC','TBO_REC',\\\n",
    "                         'ILLB_R','ILOP_R','ILP_R','PREVIS','CIG_0','CIG_1','CIG_2','CIG_3','M_Ht_In','BMI',\\\n",
    "                         'WTGAIN','RF_CESARN','OEGest_Comb'],\\\n",
    "            'target':['CA_CCHD']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AkOOjfXSSBM2"
   },
   "outputs": [],
   "source": [
    "#create missingness types:\n",
    "missing_dict = {'cont9': ['LBO_REC', 'TBO_REC'],\\\n",
    "                'cont99': ['FAGECOMB', 'PRIORTERM','PRIORLIVE', 'PRIORDEAD', 'PRECARE', 'PREVIS',\\\n",
    "                         'CIG_0', 'CIG_1', 'CIG_2', 'CIG_3', 'M_Ht_In', 'WTGAIN', 'RF_CESARN', 'OEGest_Comb'],\\\n",
    "                'cont999':['ILLB_R', 'ILP_R', 'ILOP_R'],\\\n",
    "                'cont99.9': ['BMI'],\\\n",
    "                'cat3': ['MBSTATE_REC'],\\\n",
    "                'cat8': ['MRACEHISP'],\\\n",
    "                'cat9': ['MEDUC', 'FEDUC', 'PAY', 'FRACEHISP', 'DMAR'],\\\n",
    "                'catU': ['WIC','RF_PDIAB','RF_GDIAB','RF_PHYPE',\\\n",
    "                        'RF_GHYPE','RF_EHYPE','RF_PPTERM','RF_INFTR','RF_FEDRG','RF_ARTEC','RF_CESAR','IP_GON',\\\n",
    "                        'IP_SYPH','IP_CHLAM','IP_HEPB','IP_HEPC', 'MAR_P']}\n",
    "missing_vals = [9,99,999,99.9,3,8,9,'U']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull selected variables from 2016-2018 databases in SQL and append to a single dataframe\n",
    "query18 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc.us2018\"\n",
    "\n",
    "query17 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc.us2017\"\n",
    "\n",
    "query16 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc.us2016\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhtjK-mtSHfc"
   },
   "outputs": [],
   "source": [
    "queries = [query18, query17, query16]\n",
    "            \n",
    "cchd = pd.DataFrame()\n",
    "test_cchd = pd.DataFrame()\n",
    "\n",
    "for query in queries:\n",
    "    temp = create_table_from_SQL('root','cdc',sql_pw, query)\n",
    "    train, test = split_sets(temp, 0, test_prop=0.1)\n",
    "    train = downsample_df(train, 'CA_CCHD')\n",
    "    cchd = cchd.append(train)  \n",
    "    test_cchd = test_cchd.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBmlvaXeSKkz"
   },
   "outputs": [],
   "source": [
    "chd=cchd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvP74ypSSNF8"
   },
   "outputs": [],
   "source": [
    "chd_test = test_cchd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TreOCJ5VSPLB"
   },
   "outputs": [],
   "source": [
    "target = 'CA_CCHD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_1Ms9A6SsKt"
   },
   "outputs": [],
   "source": [
    "chd = mlp_all_of_the_above(chd,chd,'CA_CCHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qx1C_CflSuWG"
   },
   "outputs": [],
   "source": [
    "chd_test = chd_test.loc[(chd_test[target]=='Y')|(chd_test[target]=='N'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAzGFZJrSwJF"
   },
   "outputs": [],
   "source": [
    "chd_test = mlp_all_of_the_above(chd_test,chd,'CA_CCHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwjoB8R6S0A7"
   },
   "outputs": [],
   "source": [
    "chd_test.MAR_P = chd_test.MAR_P.replace('U','Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PYQZciK-Ncf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDw5BaQi-Mhs"
   },
   "outputs": [],
   "source": [
    "#PHYPE\n",
    "chd = chd[chd['RF_PHYPE'] == 'Y']\n",
    "chd_test = chd_test[chd_test['RF_PHYPE'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SkAK_M2-N7d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-cPpEJdS1xz"
   },
   "outputs": [],
   "source": [
    "chd['lrg_miss_imp'] = chd.FAGECOMB_IMP | chd.FRACEHISP_IMP | chd.ILOP_R_IMP | chd.ILP_R_IMP | chd.FEDUC_IMP\n",
    "chd.drop(columns = ['FAGECOMB_IMP','FRACEHISP_IMP','ILOP_R_IMP','ILP_R_IMP','FEDUC_IMP'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-tsnBcfS3f_"
   },
   "outputs": [],
   "source": [
    "chd = LabelEncoding(chd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xp_YHIafS5oH"
   },
   "outputs": [],
   "source": [
    "chd = add_random_column_to_df(chd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLja_z3LS68c"
   },
   "outputs": [],
   "source": [
    "chd_test['lrg_miss_imp'] = chd_test.FAGECOMB_IMP | chd_test.FRACEHISP_IMP | chd_test.ILOP_R_IMP | chd_test.ILP_R_IMP | chd_test.FEDUC_IMP\n",
    "chd_test.drop(columns = ['FAGECOMB_IMP','FRACEHISP_IMP','ILOP_R_IMP','ILP_R_IMP','FEDUC_IMP'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTgptR2VTEpU"
   },
   "outputs": [],
   "source": [
    "chd_test = LabelEncoding(chd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XryMPxAJTGVU"
   },
   "outputs": [],
   "source": [
    "chd_test = add_random_column_to_df(chd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzKfMpJpTHk9"
   },
   "outputs": [],
   "source": [
    "#test train split\n",
    "target = 'CA_CCHD'\n",
    "X_train = chd.drop(target, axis=1)\n",
    "y_train = chd[[target]]\n",
    "\n",
    "X_test = chd_test.drop(target, axis=1)\n",
    "y_test = chd_test[[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLvqfXVbEZLt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "PB1hNluDV5xZ",
    "outputId": "4ac4c197-0b3a-4135-beb6-77e83610f018"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 ms, sys: 63.6 ms, total: 229 ms\n",
      "Wall time: 2.69 s\n",
      "{'leaf_size': 10, 'n_neighbors': 70}\n",
      "0.654934367744285\n",
      "CPU times: user 1.15 s, sys: 13.5 ms, total: 1.16 s\n",
      "Wall time: 1.17 s\n",
      "0.16812671445004868\n",
      "[[10835 11282]\n",
      " [   15    19]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "y_train_fit = pd.DataFrame([-1 if i == 0 else 1 for i in y_train[list(y_train.columns)[0]]])\n",
    "\n",
    "lofcv = LocalOutlierFactor(contamination = 0.5, novelty = True)\n",
    "lof_grid_param = {'n_neighbors': range(20,101,50),\n",
    "                  'leaf_size': range(10,30,5)}\n",
    "gsearch = GridSearchCV(lofcv,lof_grid_param,scoring='precision',n_jobs=2,cv=5)\n",
    "%time gsearch.fit(X_train, y_train_fit)\n",
    "\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.best_score_)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test_fit = pd.DataFrame([-1 if i == 0 else 1 for i in y_test[list(y_test.columns)[0]]])\n",
    "%time cm = confusion_matrix(y_test_fit,gsearch.predict(X_test))\n",
    "print(cm[1,1]/sum(cm[:,1])*100)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "8xHLT0C6WU-m",
    "outputId": "44652043-6e08-4350-f936-f534f40a5b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_CCHD\n",
       "0    132\n",
       "1    231\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.groupby(list(y_train.columns)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "bISrkuHYKtRi",
    "outputId": "1d21a3eb-3094-4607-d66e-255d114cedd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_CCHD\n",
       "0    22117\n",
       "1       34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.groupby(list(y_test.columns)).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "bV_5hC2gI-pJ",
    "outputId": "d35b84cf-5f37-447d-f8b1-1045a2629bf1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "y_train_fit = pd.DataFrame([-1 if i == 0 else 1 for i in y_train[list(y_train.columns)[0]]])\n",
    "\n",
    "#Initial fit\n",
    "isoForest = IsolationForest()\n",
    "isoForest.set_params(random_state=0, contamination = 0.1)\n",
    "isoForest.fit(X_train, y_train_fit) \n",
    "isofit = isoForest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUUujqXQOI3k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "oRU9PdDrJL14",
    "outputId": "5a5b5017-2077-438d-fa7e-aeab01658fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.7 ms, sys: 2.96 ms, total: 68.6 ms\n",
      "Wall time: 68.4 ms\n",
      "precision :  0.14572462746204107\n",
      "[[  875 21242]\n",
      " [    3    31]]\n",
      "{'contamination': 0.037000000000000005, 'max_features': 1, 'n_estimators': 10}\n",
      "best score: 0.6413781306829435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# set the parameter grid\n",
    "score_method = 'precision'\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "grid_para_forest = {\n",
    "    'contamination': np.linspace(0.01,0.1,11),\n",
    "    'max_features': range(1, 5),\n",
    "    'n_estimators': range(10, 120, 10)\n",
    "}\n",
    "\n",
    "# GRID SEARCH\n",
    "grid_search_isoforest = ms.GridSearchCV(isoForest, grid_para_forest, scoring=score_method, cv=10, n_jobs=-1,)\n",
    "grid_search_isoforest.fit(X_train, y_train_fit)\n",
    "\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%time cm = confusion_matrix(y_test_fit, grid_search_isoforest.predict(X_test))\n",
    "\n",
    "print(score_method, ': ', cm[1,1]/sum(cm[:,1])*100)\n",
    "print(cm)\n",
    "\n",
    "#Best Params and Score\n",
    "print(grid_search_isoforest.best_params_)\n",
    "print('best score:', grid_search_isoforest.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhJ4gcsRx70x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PHYPE_IsoF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
