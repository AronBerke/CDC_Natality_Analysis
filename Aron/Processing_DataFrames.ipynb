{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_columns = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run simple SQL query from python\n",
    "def create_table_from_SQL(user, database, password, query):\n",
    "    '''\n",
    "    - A function that returns a pandas dataframe from a SQL query in python\n",
    "    ---------------\n",
    "    - user: user for your local SQL connection in string format\n",
    "    - database: schema name where your database is stored in string format\n",
    "    - password: password to access your local SQL connection in string format\n",
    "    - query: SQL query in string format; enclose with double quotes and use single quotes\n",
    "    to designate VARCHAR values within queries; use schema_name.table_name after FROM statement\n",
    "    '''\n",
    "    import mysql.connector\n",
    "    cnx = mysql.connector.connect(user=user, database=database, password=password)\n",
    "    cursor = cnx.cursor()\n",
    "    query = query\n",
    "    cursor.execute(query)\n",
    "    df = pd.DataFrame(cursor.fetchall())\n",
    "    df.columns = cursor.column_names\n",
    "    return df\n",
    "\n",
    "#modified version of Bettina's function which creates downsampled dataset for specific defects\n",
    "#vs overall NICU admissions\n",
    "\n",
    "def downsample_df (df, variable):\n",
    "\n",
    "    '''\n",
    "    Remove undefined information on defect presence admissions (defect == 'U'),\n",
    "    create a binary target vector, and create a \"balanced\" dataframe\n",
    "    with all defect cases and matching numbers of randomly selected non-defect cases.\n",
    "    --------------------\n",
    "    df: full dataframe\n",
    "    variable: variable or defect of interest in string format\n",
    "    '''\n",
    "\n",
    "    # remove unknown class from df\n",
    "    df_no_unknown = df[df[variable].isin(['Y', 'N'])]\n",
    "\n",
    "    # Create binary target vector, NICU = yes classified as class 0\n",
    "    df_y_n = pd.DataFrame(np.where((df_no_unknown[variable] == 'Y'), 0, 1))\n",
    "\n",
    "    # Get indicies of each class' observations\n",
    "    index_class0 = np.where(df_y_n == 0)[0]\n",
    "    index_class1 = np.where(df_y_n == 1)[0]\n",
    "\n",
    "    # Get numbers of observations in class 0\n",
    "    n_class0 = len(index_class0)\n",
    "\n",
    "    # Randomly sample the same number of observations from class 1 as in class 0, without replacement\n",
    "    np.random.seed(0)\n",
    "    index_class1_downsampled = np.random.choice(index_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Create dataframes for NICU and downsampled non-NICU\n",
    "    df_defect = df_no_unknown.iloc[index_class0]\n",
    "    df_adj_NONdefect = df_no_unknown.iloc[index_class1_downsampled]\n",
    "\n",
    "    # Append into 1 dataframe\n",
    "    df_downsampled = df_defect.append(df_adj_NONdefect)\n",
    "\n",
    "    return df_downsampled\n",
    "\n",
    "# function to split out holdout test set\n",
    "def split_sets(dataframe, seed, test_prop=0.1): \n",
    "    '''\n",
    "    - A function that splits specifically a dataframe into a train and test portion\n",
    "    - Requires multiple assignment: train, test\n",
    "    ---------------\n",
    "    - dataframe: dataframe to be split\n",
    "    - seed: set seed for reproducability\n",
    "    - test_prop: takes a float - proportion of dataframe that should be allocated to the test set\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    testIdxes = np.random.choice(range(0,dataframe.shape[0]), size=round(dataframe.shape[0]*test_prop), replace=False)\n",
    "    trainIdxes = list(set(range(0,dataframe.shape[0])) - set(testIdxes))\n",
    "\n",
    "    train = dataframe.iloc[trainIdxes,:]\n",
    "    test  = dataframe.iloc[testIdxes,:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Imputation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_convert_cont_floats(df):\n",
    "    #convert continuous variables to float\n",
    "    #update to split out ordinal categorical separately\n",
    "    for x in variables['continuous']:\n",
    "        df[x]=df[x].astype('float')\n",
    "    return df\n",
    "\n",
    "def mlp_convert_nom_cat(df):\n",
    "    #convert nominal categorical variables to category\n",
    "    for x in variables['nominal_categorical']:\n",
    "        df[x]=df[x].astype('category')\n",
    "    return df\n",
    "\n",
    "def mlp_convert_ord_cat(df):\n",
    "    #convert ordinal categorical variables\n",
    "    df.DOB_MM = df.DOB_MM.astype('category')\n",
    "    df.PRECARE = df.PRECARE.astype('float')\n",
    "    return df\n",
    "\n",
    "def mlp_fill_MAR_blanks(df):\n",
    "    #change true nulls to fit missingness definitions already in the dataset\n",
    "    df.MAR_P = df.MAR_P.fillna(value='U')\n",
    "    df.DMAR = df.DMAR.fillna(value=9)\n",
    "    #df.DMAR.replace('',9, inplace=True) # need to take care of 1 vs '1'   \n",
    "#     df.DMAR.replace('1',1, inplace=True)\n",
    "#     df.DMAR.replace('2',2, inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_FRACE(df):\n",
    "    #combine FRACEHISP unknowns columns\n",
    "    df.FRACEHISP = df.FRACEHISP.replace(8,9)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_X_NA(df):\n",
    "    #assign 'X' to 'N' for RF_FEDRG RF_ARTEC and 'Y' for MAR_P since paternity assumed for married\n",
    "    for x in ['RF_FEDRG', 'RF_ARTEC']:\n",
    "        df[x].replace('X','N', inplace=True)\n",
    "    df.MAR_P.replace('X','Y', inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_reassign_ILs(df):\n",
    "    #assign 888 to mean for ILLB_R and ILP_R\n",
    "    for x in ['ILLB_R', 'ILP_R', 'ILOP_R']:\n",
    "        df[x].loc[df[x]==888][x] = df.loc[df[x]==888]['MAGER']*12\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_missing(df, target):\n",
    "    #create table of missingness proportions\n",
    "    missing_props = pd.DataFrame()\n",
    "    for i in range(0,len(missing_vals)):\n",
    "        temp = df.groupby(target)[missing_dict[list(missing_dict.keys())[i]]].apply\\\n",
    "        (lambda x: np.sum(x==missing_vals[i])/(df.shape[0]/2))\n",
    "        missing_props = pd.concat([missing_props, temp], axis=1)   \n",
    "\n",
    "    #create lists of variables with high missingness vs. low missingness\n",
    "    large_miss = list(missing_props.columns[missing_props.apply(lambda x: sum(x)>0.1, axis=0)])\n",
    "    small_miss = list(missing_props.columns[missing_props.apply(lambda x: sum(x)<0.1, axis=0)])\n",
    "\n",
    "    #sort low missingness categorical variables into types\n",
    "    small_cats = {'cat3': [], 'cat8': [], 'cat9': [], 'catU': []}\n",
    "\n",
    "    for var in small_miss:\n",
    "        if var in missing_dict['cat3']:\n",
    "            small_cats['cat3'].append(var) \n",
    "        elif var in missing_dict['cat8']:\n",
    "            small_cats['cat8'].append(var)\n",
    "        elif var in missing_dict['cat9']:\n",
    "            small_cats['cat9'].append(var)\n",
    "        elif var in missing_dict['catU']:\n",
    "            small_cats['catU'].append(var)    \n",
    "\n",
    "\n",
    "    #sort low missingness continuous variables\n",
    "    small_conts = {'cont9': [], 'cont99': [], 'cont999': [], 'cont99.9': []}\n",
    "\n",
    "    for var in small_miss:\n",
    "        if var in missing_dict['cont9']:\n",
    "            small_conts['cont9'].append(var) \n",
    "        elif var in missing_dict['cont99']:\n",
    "            small_conts['cont99'].append(var)\n",
    "        elif var in missing_dict['cont999']:\n",
    "            small_conts['cont999'].append(var)\n",
    "        elif var in missing_dict['cont99.9']:\n",
    "            small_conts['cont99.9'].append(var)\n",
    "    return small_conts, small_cats, large_miss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_impute_s_cat(df,df_w,small_cats):\n",
    "    #mode imputation of categoricals with low missingness\n",
    "    small_vals = [3,8,9,'U']\n",
    "    for i in range(0, len(small_vals)):\n",
    "        temp_lis = small_cats[list(small_cats.keys())[i]]\n",
    "        for x in temp_lis:\n",
    "            major_cat = df_w[x].value_counts().sort_values(ascending=False).index[0]\n",
    "            df[x]=df[x].replace(small_vals[i],major_cat)\n",
    "    return df\n",
    "\n",
    "def mlp_fix_MAR_P(df):\n",
    "    df.MAR_P.replace('U','Y', inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_fix_DMAR(df):\n",
    "    df.DMAR.replace(9,1, inplace=True)\n",
    "    df.DMAR.replace('9',1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_s_num(df,df_w,small_conts):\n",
    "    #median imputation of categoricals with low missingness\n",
    "    #statistical significance of relationship with target imnproves on variable by variable basis after \n",
    "    #median imputation\n",
    "    csmall_vals = [9,99,999,99.9]\n",
    "    for i in range(0, len(csmall_vals)):\n",
    "        temp_lis = small_conts[list(small_conts.keys())[i]]\n",
    "        for x in temp_lis:\n",
    "            df[x]=df[x].replace(csmall_vals[i],df_w[x].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize9(x):\n",
    "    if x==9:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def binarize99(x):\n",
    "    if x==99:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def binarize999(x):\n",
    "    if x==999:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def mlp_impute_FAGECOMB(df,df_w):\n",
    "    #Impute FAGECOMB missing vals and store whether column was imputed    \n",
    "    df['FAGECOMB_IMP'] = df.FAGECOMB.apply(lambda x: binarize99(x))\n",
    "    df.FAGECOMB.replace(99, df_w.FAGECOMB.median(),inplace = True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_ILPs(df,df_w):\n",
    "    #Impute ILOP_R and ILP_R missing vals and store whether column was imputed\n",
    "    for x in ['ILOP_R', 'ILP_R']:\n",
    "        df[x+'_IMP'] = df[x].apply(lambda x: binarize999(x))\n",
    "    for x in ['ILOP_R', 'ILP_R']:\n",
    "        df[x].replace(999,df_w[x].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_FRACE_ED(df,df_w):\n",
    "    #Impute FRACEHISP and FEDUC missing vals and store whether column was imputed\n",
    "    for x in ['FRACEHISP', 'FEDUC']:\n",
    "        df[x+'_IMP'] = df[x].apply(lambda x: binarize9(x))\n",
    "    for x in ['FRACEHISP', 'FEDUC']:\n",
    "        df[x].replace(9,df_w[x].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def mlp_impute_combine(df):\n",
    "    #Combine imputed flag columns into one\n",
    "    df['lrg_miss_imp'] = df.FAGECOMB_IMP|df.ILOP_R_IMP|df.ILP_R_IMP|df.FRACEHISP_IMP|df.FEDUC_IMP\n",
    "    df = df.drop(['FAGECOMB_IMP', 'ILOP_R_IMP', 'ILP_R_IMP','FRACEHISP_IMP','FEDUC_IMP'],axis=1)\n",
    "    return df\n",
    "\n",
    "def mlp_drop_highcoll(df):\n",
    "    df = df.drop(['RF_CESAR', 'LBO_REC', 'TBO_REC', 'RF_INFTR', 'CIG_2', 'CIG_3', 'ILP_R'],axis=1)\n",
    "    return df\n",
    "\n",
    "def binarize_target(df,target):\n",
    "    df[target]=np.where(df[target]=='Y',1,0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_all_of_the_above(df,df_w,target):\n",
    "    df = mlp_fill_MAR_blanks(df)\n",
    "    df = mlp_reassign_FRACE(df)\n",
    "    df = mlp_reassign_X_NA(df)\n",
    "    df = mlp_reassign_ILs(df)\n",
    "    df = mlp_convert_cont_floats(df)\n",
    "    small_conts, small_cats, large_miss = measure_missing(df,target)\n",
    "    df = mlp_impute_s_cat(df,df_w,small_cats)\n",
    "    df = mlp_fix_MAR_P(df)\n",
    "    df = mlp_fix_DMAR(df)\n",
    "    df = mlp_impute_s_num(df,df_w,small_conts)\n",
    "    df = mlp_impute_FAGECOMB(df,df_w)\n",
    "    df = mlp_impute_ILPs(df,df_w)\n",
    "    df = mlp_impute_FRACE_ED(df,df_w)\n",
    "    df = binarize_target(df, target)\n",
    "    df = mlp_convert_nom_cat(df)\n",
    "    df = mlp_convert_ord_cat(df)\n",
    "    df = mlp_drop_highcoll(df)\n",
    "    df = mlp_impute_combine(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in DataFrame (10% holdout, 1:1 downsample train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,RF_CESARN,OEGest_Comb,CA_CCHD'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# begin dictionary of columns to analyze for CCHD - includes pre-pregnancy and gestational features\n",
    "# features re: delivery and labor are not useful for this use case\n",
    "variables = {'nominal_categorical':['MBSTATE_REC','MRACEHISP','MAR_P','DMAR','MEDUC','FRACEHISP',\\\n",
    "                                    'FEDUC','WIC','RF_PDIAB','RF_GDIAB','RF_PHYPE','RF_GHYPE',\\\n",
    "                                    'RF_EHYPE','RF_PPTERM','RF_INFTR','RF_FEDRG','RF_ARTEC','RF_CESAR',\\\n",
    "                                  'IP_GON','IP_SYPH','IP_CHLAM','IP_HEPB','IP_HEPC', 'PAY', 'SEX'],\\\n",
    "           'ordinal_categorical':['PRECARE', 'DOB_MM'],\\\n",
    "           'continuous':['MAGER', 'FAGECOMB','PRIORTERM','PRIORLIVE','PRIORDEAD','LBO_REC','TBO_REC',\\\n",
    "                         'ILLB_R','ILOP_R','ILP_R','PREVIS','CIG_0','CIG_1','CIG_2','CIG_3','M_Ht_In','BMI',\\\n",
    "                         'WTGAIN','RF_CESARN','OEGest_Comb'],\\\n",
    "            'target':['CA_CCHD']}\n",
    "\n",
    "vrs = variables['nominal_categorical']+variables['ordinal_categorical']+variables['continuous']+variables['target']\n",
    "\",\".join(vrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull selected variables from 2016-2018 databases in SQL and append to a single dataframe\n",
    "query18 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc_project.cdc_2018_full\"\n",
    "\n",
    "query17 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc_project.cdc_2017_full\"\n",
    "\n",
    "query16 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc_project.cdc_2016_full\"\n",
    "\n",
    "queries = [query18, query17, query16]\n",
    "            \n",
    "cchd = pd.DataFrame()\n",
    "test_cchd = pd.DataFrame()\n",
    "\n",
    "for query in queries:\n",
    "    temp = create_table_from_SQL('root','cdc_project','******', query)\n",
    "    train, test = split_sets(temp, 0, test_prop=0.1)\n",
    "    train = downsample_df(train, 'CA_CCHD')\n",
    "    cchd = cchd.append(train)  \n",
    "    test_cchd = test_cchd.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dict = {'cont9': ['LBO_REC', 'TBO_REC'],\\\n",
    "                'cont99': ['FAGECOMB', 'PRIORTERM','PRIORLIVE', 'PRIORDEAD', 'PRECARE', 'PREVIS',\\\n",
    "                         'CIG_0', 'CIG_1', 'CIG_2', 'CIG_3', 'M_Ht_In', 'WTGAIN', 'RF_CESARN', 'OEGest_Comb'],\\\n",
    "                'cont999':['ILLB_R', 'ILP_R', 'ILOP_R'],\\\n",
    "                'cont99.9': ['BMI'],\\\n",
    "                'cat3': ['MBSTATE_REC'],\\\n",
    "                'cat8': ['MRACEHISP'],\\\n",
    "                'cat9': ['MEDUC', 'FEDUC', 'PAY', 'FRACEHISP', 'DMAR'],\\\n",
    "                'catU': ['WIC','RF_PDIAB','RF_GDIAB','RF_PHYPE',\\\n",
    "                        'RF_GHYPE','RF_EHYPE','RF_PPTERM','RF_INFTR','RF_FEDRG','RF_ARTEC','RF_CESAR','IP_GON',\\\n",
    "                        'IP_SYPH','IP_CHLAM','IP_HEPB','IP_HEPC', 'MAR_P']}\n",
    "missing_vals = [9,99,999,99.9,3,8,9,'U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cchd = pd.read_csv('Datasets/baseline_test.csv')\n",
    "cchd = pd.read_csv('Datasets/baseline_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cchd_all_imp = mlp_all_of_the_above(cchd,cchd,'CA_CCHD')\n",
    "cchd_all_imp_test = mlp_all_of_the_above(test_cchd,cchd,'CA_CCHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    735116\n",
       "2.0    427123\n",
       "Name: DMAR, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cchd_all_imp_test.DMAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cchd_all_imp_test.to_csv('Datasets/cchd_allimp_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDIAB population (10% holdout, 10:1 downsample) - All Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##update to control sampling ratio\n",
    "def downsample_df (df, variable, ratio):\n",
    "\n",
    "    '''\n",
    "    Remove undefined information on defect presence admissions (defect == 'U'),\n",
    "    create a binary target vector, and create a \"balanced\" dataframe\n",
    "    with all defect cases and matching numbers of randomly selected non-defect cases.\n",
    "    --------------------\n",
    "    df: full dataframe\n",
    "    variable: variable or defect of interest in string format\n",
    "    ratio: takes an integer, the factor by which to scale the sample where variable = 'Y'\n",
    "    '''\n",
    "\n",
    "    # remove unknown class from df\n",
    "    df_no_unknown = df[df[variable].isin(['Y', 'N'])]\n",
    "\n",
    "    # Create binary target vector, NICU = yes classified as class 0\n",
    "    df_y_n = pd.DataFrame(np.where((df_no_unknown[variable] == 'Y'), 0, 1))\n",
    "\n",
    "    # Get indicies of each class' observations\n",
    "    index_class0 = np.where(df_y_n == 0)[0]\n",
    "    index_class1 = np.where(df_y_n == 1)[0]\n",
    "\n",
    "    # Get numbers of observations in class 0\n",
    "    n_class0 = len(index_class0)*ratio\n",
    "\n",
    "    # Randomly sample the same number of observations from class 1 as in class 0, without replacement\n",
    "    np.random.seed(0)\n",
    "    index_class1_downsampled = np.random.choice(index_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Create dataframes for NICU and downsampled non-NICU\n",
    "    df_defect = df_no_unknown.iloc[index_class0]\n",
    "    df_adj_NONdefect = df_no_unknown.iloc[index_class1_downsampled]\n",
    "\n",
    "    # Append into 1 dataframe\n",
    "    df_downsampled = df_defect.append(df_adj_NONdefect)\n",
    "\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query16 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD,\\\n",
    "            FROM cdc_project.cdc_2016_full\\\n",
    "            WHERE RF_PDIAB = 'Y'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull selected variables from 2016-2018 databases in SQL and append to a single dataframe\n",
    "query18 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc_project.cdc_2018_full\"\n",
    "\n",
    "query17 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc_project.cdc_2017_full\"\n",
    "\n",
    "query16 = \"SELECT MBSTATE_REC,MRACEHISP,MAR_P,DMAR,MEDUC,FRACEHISP,FEDUC,WIC,RF_PDIAB,RF_GDIAB,RF_PHYPE,\\\n",
    "                RF_GHYPE,RF_EHYPE,RF_PPTERM,RF_INFTR,RF_FEDRG,RF_ARTEC,RF_CESAR,IP_GON,IP_SYPH,IP_CHLAM,\\\n",
    "                IP_HEPB,IP_HEPC,PAY,SEX,PRECARE,DOB_MM,MAGER,FAGECOMB,PRIORTERM,PRIORLIVE,PRIORDEAD,\\\n",
    "                LBO_REC,TBO_REC,ILLB_R,ILOP_R,ILP_R,PREVIS,CIG_0,CIG_1,CIG_2,CIG_3,M_Ht_In,BMI,WTGAIN,\\\n",
    "                RF_CESARN,OEGest_Comb,CA_CCHD\\\n",
    "         FROM cdc_project.cdc_2016_full\"\n",
    "\n",
    "queries = [query18, query17, query16]\n",
    "            \n",
    "cchd = pd.DataFrame()\n",
    "test_cchd = pd.DataFrame()\n",
    "\n",
    "for query in queries:\n",
    "    temp = create_table_from_SQL('root','cdc_project','******', query)\n",
    "    train, test = split_sets(temp, 0, test_prop=0.1)\n",
    "    train = downsample_df(train, 'CA_CCHD')\n",
    "    cchd = cchd.append(train)  \n",
    "    test_cchd = test_cchd.append(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
